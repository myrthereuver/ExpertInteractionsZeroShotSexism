{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "golden-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reported-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.13.0\n",
      "-e git+https://github.com/yz-joey/ACLPUB.git@b8df276e8f2e14e96a424a025ef010aed826d79c#egg=aclpub_check\n",
      "adal==1.2.7\n",
      "aiohttp==3.8.1\n",
      "aiosignal==1.2.0\n",
      "annotated-types==0.7.0\n",
      "ansiwrap==0.8.4\n",
      "anyio==4.6.0\n",
      "appnope==0.1.2\n",
      "argon2-cffi==20.1.0\n",
      "astunparse==1.6.3\n",
      "async-generator==1.10\n",
      "async-timeout==4.0.2\n",
      "attrs==21.2.0\n",
      "azure-core==1.26.1\n",
      "Babel==2.9.1\n",
      "backcall==0.2.0\n",
      "backports.entry-points-selectable==1.1.0\n",
      "bertopic==0.16.3\n",
      "bleach==3.3.0\n",
      "blis==0.7.9\n",
      "Brotli==1.0.9\n",
      "cachetools==4.2.2\n",
      "catalogue==2.0.8\n",
      "certifi==2021.5.30\n",
      "cffi==1.14.5\n",
      "chardet==4.0.0\n",
      "charset-normalizer==2.1.0\n",
      "clang==5.0\n",
      "click==7.1.2\n",
      "codecov==2.1.13\n",
      "comm==0.2.2\n",
      "confection==0.0.4\n",
      "coverage==7.5.3\n",
      "crowdtruth==2.1\n",
      "cryptography==38.0.3\n",
      "cycler==0.10.0\n",
      "cymem==2.0.7\n",
      "datasets==2.3.2\n",
      "dateparser==1.2.0\n",
      "decorator==4.4.2\n",
      "defusedxml==0.7.1\n",
      "dill==0.3.4\n",
      "distlib==0.3.2\n",
      "distro==1.9.0\n",
      "entrypoints==0.3\n",
      "exceptiongroup==1.0.4\n",
      "filelock==3.0.12\n",
      "fire==0.4.0\n",
      "Flask==1.1.2\n",
      "flatbuffers==1.12\n",
      "frozenlist==1.3.0\n",
      "fsspec==2024.3.1\n",
      "gast==0.4.0\n",
      "gensim==3.8.3\n",
      "gevent==22.10.2\n",
      "google-auth==1.35.0\n",
      "google-auth-oauthlib==0.4.5\n",
      "google-pasta==0.2.0\n",
      "greenlet==2.0.1\n",
      "grpcio==1.39.0\n",
      "h11==0.14.0\n",
      "h5py==3.1.0\n",
      "hdbscan==0.8.38.post1\n",
      "httpcore==1.0.6\n",
      "httpx==0.27.2\n",
      "huggingface==0.0.1\n",
      "huggingface-hub==0.22.2\n",
      "hypothesis==6.58.0\n",
      "idna==2.10\n",
      "ipykernel==5.5.5\n",
      "ipython==7.24.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.1.2\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.1.2\n",
      "jedi==0.18.0\n",
      "Jinja2==3.0.1\n",
      "jiter==0.6.1\n",
      "joblib==1.0.1\n",
      "json5==0.9.5\n",
      "jsonschema==3.2.0\n",
      "jupyter-client==7.4.7\n",
      "jupyter-core==5.0.0\n",
      "jupyter-server==1.8.0\n",
      "jupyterlab==3.0.16\n",
      "jupyterlab-pygments==0.1.2\n",
      "jupyterlab-server==2.5.2\n",
      "jupyterlab-widgets==3.0.10\n",
      "keras==2.6.0\n",
      "Keras-Preprocessing==1.1.2\n",
      "keras2onnx==1.7.0\n",
      "kiwisolver==1.3.1\n",
      "langcodes==3.3.0\n",
      "lightgbm==3.3.3\n",
      "llvmlite==0.39.1\n",
      "Markdown==3.3.4\n",
      "MarkupSafe==2.0.1\n",
      "matplotlib==3.4.2\n",
      "matplotlib-inline==0.1.2\n",
      "memory-profiler==0.61.0\n",
      "mistune==0.8.4\n",
      "mpmath==1.2.1\n",
      "msgpack==1.0.4\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4\n",
      "multidict==6.0.2\n",
      "multiprocess==0.70.12.2\n",
      "murmurhash==1.0.9\n",
      "mypy-extensions==0.4.3\n",
      "nbclassic==0.3.1\n",
      "nbclient==0.5.3\n",
      "nbconvert==6.0.7\n",
      "nbformat==5.1.3\n",
      "nest-asyncio==1.5.6\n",
      "networkx==2.5.1\n",
      "nltk==3.7\n",
      "notebook==6.4.12\n",
      "numba==0.56.4\n",
      "numpy==1.22.4\n",
      "oauthlib==3.1.1\n",
      "onnx==1.10.1\n",
      "onnxconverter-common==1.8.1\n",
      "openai==1.51.2\n",
      "opt-einsum==3.3.0\n",
      "packaging==21.3\n",
      "pandas==1.4.2\n",
      "pandera==0.13.4\n",
      "pandocfilters==1.4.3\n",
      "papermill==2.4.0\n",
      "parso==0.8.2\n",
      "pathy==0.10.1\n",
      "patsy==0.5.3\n",
      "pdfminer.six==20200517\n",
      "pdfplumber==0.5.28\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==8.2.0\n",
      "platformdirs==2.2.0\n",
      "plotly==5.24.1\n",
      "powerlaw==1.5\n",
      "preshed==3.0.8\n",
      "prometheus-client==0.10.1\n",
      "prompt-toolkit==3.0.18\n",
      "protobuf==3.17.3\n",
      "psutil==5.9.4\n",
      "ptyprocess==0.7.0\n",
      "py4j==0.10.9.7\n",
      "pyarrow==8.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.20\n",
      "pycryptodome==3.10.1\n",
      "pydantic==2.9.2\n",
      "pydantic-core==2.23.4\n",
      "Pygments==2.9.0\n",
      "pyhere==1.0.0\n",
      "PyJWT==2.6.0\n",
      "pymodm==0.4.3\n",
      "pymongo==3.13.0\n",
      "pynndescent==0.5.13\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.17.3\n",
      "python-dateutil==2.8.2\n",
      "pytz==2021.1\n",
      "PyYAML==5.4.1\n",
      "pyzmq==24.0.1\n",
      "qtconsole==5.4.0\n",
      "QtPy==2.3.0\n",
      "regex==2021.8.28\n",
      "requests==2.25.1\n",
      "requests-oauthlib==1.3.0\n",
      "responses==0.18.0\n",
      "retrying==1.3.3\n",
      "rsa==4.7.2\n",
      "sacremoses==0.0.45\n",
      "safetensors==0.4.2\n",
      "scikit-learn==0.24.2\n",
      "scikit-surprise==1.1.3\n",
      "scipy==1.6.3\n",
      "seaborn==0.13.0\n",
      "Send2Trash==1.8.0\n",
      "sentence-transformers==2.6.1\n",
      "six==1.15.0\n",
      "sklearn==0.0\n",
      "smart-open==5.2.1\n",
      "sniffio==1.2.0\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.3.2.post1\n",
      "spacy==3.5.3\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.4\n",
      "srsly==2.4.5\n",
      "statsmodels==0.13.5\n",
      "sympy==1.12.1rc1\n",
      "tabulate==0.9.0\n",
      "tenacity==8.1.0\n",
      "tensorboard==2.6.0\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.0\n",
      "tensorflow==2.6.0\n",
      "tensorflow-cpu==2.6.0\n",
      "tensorflow-estimator==2.6.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.10.0\n",
      "testpath==0.5.0\n",
      "textwrap3==0.9.2\n",
      "thinc==8.1.10\n",
      "threadpoolctl==2.1.0\n",
      "tokenizers==0.15.2\n",
      "torch==2.3.0.dev20240227\n",
      "torchvision==0.18.0.dev20240227\n",
      "tornado==6.2\n",
      "tqdm==4.64.0\n",
      "traitlets==5.0.5\n",
      "transformers==4.39.3\n",
      "typer==0.3.2\n",
      "typing-extensions==4.11.0\n",
      "typing-inspect==0.8.0\n",
      "tzlocal==5.2\n",
      "umap-learn==0.5.6\n",
      "urllib3==1.26.5\n",
      "virtualenv==20.7.2\n",
      "Wand==0.6.6\n",
      "wasabi==0.10.1\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.0.1\n",
      "Werkzeug==2.0.1\n",
      "widgetsnbextension==4.0.10\n",
      "wrapt==1.12.1\n",
      "xxhash==2.0.2\n",
      "yarl==1.7.2\n",
      "zope.event==4.5.0\n",
      "zope.interface==5.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f8924-3bc8-4771-b8c5-51b832813a5f",
   "metadata": {},
   "source": [
    "### Open AI: setting key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laden-hammer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-697e04c9e2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'key' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9982f135-e64c-43fd-9597-6307839fd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_4o = \"gpt-4-turbo-2024-04-09\"\n",
    "GPT_3 = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b2ec94-fb6e-44f3-aeb3-58856eb8ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types import Completion, CompletionChoice, CompletionUsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987269a1-507f-4a9a-ab40-d67de98ca4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "contrary-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(model=GPT_4o, messages=[{\"role\": \"user\", \"content\": \"Hello world!\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "living-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-closer",
   "metadata": {},
   "source": [
    "## Prompt Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "strong-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "## original prompt\n",
    "def create_prompt_definition_sexism(definition):\n",
    "\n",
    "    prompt = f\"Your task is to annotate if a piece of text is sexist or not.\\\n",
    "    Later, you get a detailed definition of sexism. \\\n",
    "    Definition of sexism: {definition} \"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c98bc1-b708-4bb9-b113-72703900de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text1 = \"women are capable of commentating on football matches\" \n",
    "test_text2 = \"women are weak and belong in the kitchen\"\n",
    "\n",
    "test_definition = \"sexism is when men comment on women\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a09b8360-5038-4c75-b34e-ad3667b29e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt_definition_sexism(test_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d9a8c4-18e3-4ccb-a4ff-f379c07ba1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: sexism is when men comment on women '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b391c8fe-a60e-4cd8-b3da-79625b4d11b7",
   "metadata": {},
   "source": [
    "#### import definitions, put in dictionary per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65886ae0-34f9-4989-b076-fbb3cabf0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions_data = pd.read_csv(\"../../data/definitions/Sexism/Definitions_Interaction_ds - Definitions_Interaction_ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0aa6735-02b7-445e-8924-c647d511a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def_dict = defaultdict()\n",
    "\n",
    "for _, row in definitions_data.iterrows():\n",
    "    participant_dict = defaultdict()\n",
    "    participant_dict[\"chosen_definition_10\"] = row[\"chosen_definition_10\"]\n",
    "    participant_dict[\"def_ChatGPT_1\"] = row[\"def_ChatGPT_1\"]\n",
    "    participant_dict[\"participant_definition\"] = row[\"participant_define\"]\n",
    "    try: \n",
    "        participant_dict[\"definition_category\"] = row[\"Indira Definition Category\"].split(\" detail\")[0]\n",
    "    except:\n",
    "        participant_dict[\"definition_category\"] = \"unk\"\n",
    "    def_dict[row[\"ResponseId\"]] = participant_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ac647f-c1f9-451f-9c52-4634c406c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759129e7-ad10-4730-83f1-c578562333c7",
   "metadata": {},
   "source": [
    "#### add definition prompts to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc15702e-047e-4189-8a6c-75fb98c20f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in def_dict.keys():\n",
    "    def_dict[participant][\"prompt_definition_chosen_10\"] = create_prompt_definition_sexism(def_dict[participant][\"chosen_definition_10\"])\n",
    "    def_dict[participant][\"prompt_definition_ChatGPT_1\"] = create_prompt_definition_sexism(def_dict[participant][\"def_ChatGPT_1\"])\n",
    "    def_dict[participant][\"prompt_definition_participant\"] = create_prompt_definition_sexism(def_dict[participant][\"participant_definition\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc6bccc9-db4f-4b84-b3da-aeb0b0bc0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38c712-a820-4dce-9220-f4bb09261d9d",
   "metadata": {},
   "source": [
    "#### Add texts to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e6d85a3-bbb6-45e5-8208-a815e495d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_texts_to_prompts(prompt_dict, prompt_version, text):\n",
    "    preamble = prompt_dict[prompt_version]\n",
    "    prompt = preamble + f\"With this definition in mind and a piece of text, please reply with either of the three options and nothing else: 1) sexist, 2) non-sexist, 3) can’t say. Please use the last option as little as possible and if you do, provide a one sentence explanation. Do not give an explanation if you pick ’sexist’ or ’non-sexist’. \\\n",
    "    We are ready to begin now. Is this sentence sexist based on the past definition’ : {text} - ’Please reply with either of the three options and nothing else: 1) sexist, 2) non-sexist, 3) can’t say.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "37131edc-b147-40c7-a802-595405e8ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760c390-1fc0-43dc-8cbb-dde912ac9ff5",
   "metadata": {},
   "source": [
    "### Classification test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44489cc8-d973-408b-b072-d9eb31446f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = add_texts_to_prompts(participant_dict, \n",
    "                             \"prompt_definition_participant\", \n",
    "                            \"Girls are dumber than boys\")\n",
    "\n",
    "completion = client.chat.completions.create(model=GPT_4o, \n",
    "                                            messages=[{\"role\": \"user\", \n",
    "                                                       \"content\": prompt}],n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff362f0-716b-4b0c-bda2-81073586b41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) sexist'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443df79-b840-432d-8619-7470c56cbae2",
   "metadata": {},
   "source": [
    "### Test prompts with definitions on our sexism datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7617114b-cb25-46f7-bc23-45e0db48728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = ['in_domain', 'out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3',# 'out_of_domain_4', \n",
    "             'hatecheck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c53e6369-1ded-49a8-9508-75d0283fa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_names = ['sexism']\n",
    "\n",
    "construct = 'sexism'\n",
    "pos_label = 'sexist'\n",
    "neg_label = 'non-sexist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae179e84-fbcd-4c6f-8f06-0b6de55bdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    test_set_data[construct] = {}\n",
    "    for test_set in test_sets:\n",
    "        test_path = '../../data/data/%s/test/%s.csv' %(construct, test_set)\n",
    "        test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t').sample(n=500, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "025e748e-b8c1-44e4-9500-49e97eba8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test_set_data[\"sexism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab1f6989-bb6e-47a2-b370-49393c832c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv(\"../../data/data/sexism/train/data_sample.tsv\",  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39f8f102-7d90-45cf-b498-717adf0096da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sexism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d654925ce2c6bd7334795bd</td>\n",
       "      <td>i can't take girls serious when talk about sports</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d654901ce2c6bd733475c03</td>\n",
       "      <td>#womensday  Women have surely outdone men if t...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d65490ace2c6bd7334763c0</td>\n",
       "      <td>You've undercooked eggs and probably poisoned ...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf5d5</td>\n",
       "      <td>A daughter in a family should have the same pr...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d654921ce2c6bd733478ac5</td>\n",
       "      <td>a womans place IS the kitchen</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5d654925ce2c6bd7334795bd   \n",
       "1  5d654901ce2c6bd733475c03   \n",
       "2  5d65490ace2c6bd7334763c0   \n",
       "3  5ddc4fe8174b03a4c6aaf5d5   \n",
       "4  5d654921ce2c6bd733478ac5   \n",
       "\n",
       "                                                text      sexism  \n",
       "0  i can't take girls serious when talk about sports      sexist  \n",
       "1  #womensday  Women have surely outdone men if t...      sexist  \n",
       "2  You've undercooked eggs and probably poisoned ...  non-sexist  \n",
       "3  A daughter in a family should have the same pr...  non-sexist  \n",
       "4                      a womans place IS the kitchen      sexist  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e5d1055-1443-4dcc-910a-3e06310df17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EXP_1', 'EXP_2', 'EXP_3', 'EXP_4', 'EXP_5', 'EXP_6', 'EXP_7', 'EXP_8', 'EXP_9', 'EXP_10', 'EXP_11'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91339772-6c14-4955-98a0-7699f9ccd45f",
   "metadata": {},
   "source": [
    "### clean_def_dict with empty definitions (participants didn't do def experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2eededae-34dd-4026-a147-93c0664ec96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_def_dict with empty definitions (participants didn't do def experiment)\n",
    "participants_to_remove = ('EXP_7', 'EXP_8')\n",
    "for k in participants_to_remove:\n",
    "    def_dict.pop(k, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97809941-45a9-412f-9e54-bfa9681e1b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EXP_1', 'EXP_2', 'EXP_3', 'EXP_4', 'EXP_5', 'EXP_6', 'EXP_9', 'EXP_10', 'EXP_11'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a57a32-b4ec-4f71-ad1c-ce220c9a0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_data[\"sexism\"].items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fec44b-ebd7-4ec2-906f-b1b15e92d51e",
   "metadata": {},
   "source": [
    "## Classification w open AI models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6973cab-0fa0-430a-9fa5-3a800daa1588",
   "metadata": {},
   "source": [
    "#### We run the following loop for all texts for each of the three definition dictionaries: (1) for the participant definitions, (2) for the GPT definitions, and (3) for the co-created definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85512806-4dc3-4c01-8610-40a03250ed42",
   "metadata": {},
   "source": [
    "### Loop 1: participant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02e513e5-b6e0-469b-8e19-358126c4ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_participantdef_GPT4o = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c3a0d53-24e2-42fa-a4cd-acbdac99dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_participantdef_GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "35023cf4-9a2a-4530-a3a3-5a3000f58e7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-bd080973c867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     responses = client.chat.completions.create(model=GPT_4o,\n\u001b[0m\u001b[1;32m     28\u001b[0m                                                                messages=[{\"role\": \"user\", \n\u001b[1;32m     29\u001b[0m                                                                       \"content\": prompt}],\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    740\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    741\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     def patch(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         return self._process_response(\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# for each test set\n",
    "# for domain, test_set in test_set_data[\"sexism\"].items():\n",
    "\n",
    "for data in [\"hatecheck\", \"out_of_domain_2\", \"out_of_domain_3\"]:\n",
    "    domain = data\n",
    "    test_set = test_set_data[\"sexism\"][domain]\n",
    "    # we have a result dictionary of dictionaries per participant\n",
    "    result_dict = defaultdict()\n",
    "    for participant, participant_dict in def_dict.items():\n",
    "            part_dict = defaultdict()\n",
    "            for _, row in test_set_data[\"sexism\"][domain].iterrows():\n",
    "                prompt = add_texts_to_prompts(participant_dict, \n",
    "                                          \"prompt_definition_participant\", \n",
    "                                          row[\"text\"])\n",
    "                try:\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        n=2,\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0)                                                                    \n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                         n = 2, \n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0) \n",
    "                part_dict[row[\"_id\"]] = [responses.choices[0].message.content,\n",
    "                                         responses.choices[1].message.content]\n",
    "            results_participantdef_GPT4o[participant] = part_dict \n",
    "            result_dict['GPT4o'] = results_participantdef_GPT4o\n",
    "    test_set_data['sexism'][domain][\"results_stabilityCheck\"] = str(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e92c2-308d-422d-9dd3-607b6a0dfc49",
   "metadata": {},
   "source": [
    "### writing the dictionary of results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "6e81c76c-aa59-475a-8877-31bd6f3090b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"GESIS_stability_n2.txt\", \"w+\") as f:\n",
    "    f.write(str(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "472cf597-8474-4a11-9c58-d15b6d2a57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('all_results_dict_of_dfs_stability_n2_GESIS.pickle', 'wb') as f:\n",
    "    pickle.dump(test_set_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac577e01-0326-4af8-818d-2ed063a88672",
   "metadata": {},
   "source": [
    "### Loop 2: GPT definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016d20f-53fa-4006-bcfa-4d345d30dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each test set\n",
    "for domain, test_set in test_set_data[\"sexism\"].items():\n",
    "    # we have a result dictionary of dictionaries per participant\n",
    "    result_dict = defaultdict()\n",
    "    for participant, participant_dict in def_dict.items():\n",
    "            part_dict = defaultdict()\n",
    "            for _, row in test_set_data[\"sexism\"][domain].iterrows():\n",
    "                prompt = add_texts_to_prompts(participant_dict, \n",
    "                                          \"prompt_definition_ChatGPT_1\", \n",
    "                                          row[\"text\"])\n",
    "                try:\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0)                                                                    \n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0) \n",
    "                part_dict[row[\"_id\"]] = responses.choices[0].message.content                                                          \n",
    "            results_participantdef_GPT4o[participant] = part_dict \n",
    "            result_dict[domain] = results_participantdef_GPT4o\n",
    "    test_set_data['sexism'][domain][\"results_GPTdef1\"] = str(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929eae4-2468-4069-b3e8-8c619f0415cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F1_500items_GPTdef1.txt\", \"w+\") as f:\n",
    "    f.write(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc4784-8c28-4147-9755-19e808efab44",
   "metadata": {},
   "source": [
    "### Loop 3: co-created definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "572d285b-14a3-4fb4-8dd0-a4993f4d1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each test set\n",
    "for domain, test_set in test_set_data[\"sexism\"].items():\n",
    "    # we have a result dictionary of dictionaries per participant\n",
    "    result_dict = defaultdict()\n",
    "    for participant, participant_dict in def_dict.items():\n",
    "            part_dict = defaultdict()\n",
    "            for _, row in test_set_data[\"sexism\"][domain].iterrows():\n",
    "                prompt = add_texts_to_prompts(participant_dict, \n",
    "                                          \"prompt_definition_chosen_10\", \n",
    "                                          row[\"text\"])\n",
    "                try:\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0)                                                                    \n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0) \n",
    "                part_dict[row[\"_id\"]] = responses.choices[0].message.content                                                          \n",
    "            results_participantdef_GPT4o[participant] = part_dict \n",
    "            result_dict[domain] = results_participantdef_GPT4o\n",
    "    test_set_data['sexism'][domain][\"results_GPTdef10\"] = str(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f97780-25d9-4b2a-af0b-26154f1a16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_data[\"sexism\"][\"in_domain\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "322f6a7e-cda2-4015-b37c-7549785f0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F1_500items_GPTdef10.txt\", \"w+\") as f:\n",
    "    f.write(str(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "bd2632e0-82a0-476f-bcf5-3c7d0d3337de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Loop3_results_dict_of_dfs.pickle', 'wb') as f:\n",
    "    pickle.dump(test_set_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08b993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_test = pd.read_pickle(\"Loop3_results_dict_of_dfs.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab856108",
   "metadata": {},
   "source": [
    "### Make metrics dataframe for GPT definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a64f4416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "definitions = [\"results_GPTdef10\", \"results_GPTdef1\"]\n",
    "experts = [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\", \"EXP_10\", \"EXP_11\"]\n",
    "\n",
    "for dataset in results_all[\"sexism\"].keys():\n",
    "    for definition in definitions:\n",
    "        for expert in experts: \n",
    "            for i in results_all[\"sexism\"][dataset][definition][:2]:\n",
    "                result_dict = eval(i)\n",
    "#                 print(result_dict)\n",
    "                try:\n",
    "                    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[dataset][expert].values()]\n",
    "                    labels = [\"non-sexist\" if i == \"can’t say\" or i == \"can't say\" else i for i in labels] \n",
    "                    truth = results_all[\"sexism\"][dataset][\"sexism\"].tolist()\n",
    "                    scores = classification_report(truth, labels, output_dict=True)\n",
    "\n",
    "                    temp_dict = pd.DataFrame()\n",
    "\n",
    "                    temp_dict[\"definition\"] = [definition]\n",
    "                    temp_dict[\"expert\"] = expert\n",
    "                    temp_dict[\"dataset\"] = dataset\n",
    "                    temp_dict[\"scores\"] = [scores]\n",
    "\n",
    "                    metrics_df = pd.concat([metrics_df, temp_dict])\n",
    "                except:\n",
    "                    print(\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82a011",
   "metadata": {},
   "source": [
    "### Add the participant definitions to this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4273f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in results_all[\"sexism\"].keys():\n",
    "    for definition in [\"results\"]:\n",
    "        for expert in experts: \n",
    "            for i in results_all[\"sexism\"][dataset][definition][:2]:\n",
    "                result_dict = eval(i)\n",
    "#                 print(result_dict)\n",
    "                try:\n",
    "                    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"GPT4o\"][expert].values()]\n",
    "                    labels = [\"non-sexist\" if i == \"can’t say\" or i == \"can't say\" else i for i in labels] \n",
    "                    truth = results_all[\"sexism\"][dataset][\"sexism\"].tolist()\n",
    "                    scores = classification_report(truth, labels, output_dict=True)\n",
    "\n",
    "                    temp_dict = pd.DataFrame()\n",
    "\n",
    "                    temp_dict[\"definition\"] = [definition]\n",
    "                    temp_dict[\"expert\"] = expert\n",
    "                    temp_dict[\"dataset\"] = dataset\n",
    "                    temp_dict[\"scores\"] = [scores]\n",
    "\n",
    "                    metrics_df = pd.concat([metrics_df, temp_dict])\n",
    "                except:\n",
    "                    print(\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7f73eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df[\"definition\"] = metrics_df[\"definition\"].replace(\"results_GPTdef10\", \"hybrid\")\n",
    "metrics_df[\"definition\"] = metrics_df[\"definition\"].replace(\"results_GPTdef1\", \"GPT\")\n",
    "metrics_df[\"definition\"] = metrics_df[\"definition\"].replace(\"results\", \"participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6f96a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'non-sexist': {'precision': 0.9333333333333333, 'recall': 0.7608695652173914, 'f1-score': 0.8383233532934132, 'support': 276}, 'sexist': {'precision': 0.76, 'recall': 0.9330357142857143, 'f1-score': 0.8376753507014029, 'support': 224}, 'accuracy': 0.838, 'macro avg': {'precision': 0.8466666666666667, 'recall': 0.8469526397515528, 'f1-score': 0.837999351997408, 'support': 500}, 'weighted avg': {'precision': 0.8556800000000001, 'recall': 0.838, 'f1-score': 0.8380330481321926, 'support': 500}}\n"
     ]
    }
   ],
   "source": [
    "for i in metrics_df[\"scores\"][:1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b81686",
   "metadata": {},
   "source": [
    "### add individual metrics to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f95039b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definition</th>\n",
       "      <th>expert</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scores</th>\n",
       "      <th>F1</th>\n",
       "      <th>sexist_F1</th>\n",
       "      <th>non_sexist_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0.831957</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0.831957</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_3</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.806584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_9</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.267857142857142...</td>\n",
       "      <td>0.483775</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.336134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     definition  expert    dataset  \\\n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_3  in_domain   \n",
       "..          ...     ...        ...   \n",
       "0   participant   EXP_9  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "\n",
       "                                               scores        F1  sexist_F1  \\\n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.837999   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.837999   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...  0.831957   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...  0.831957   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.811852   0.817121   \n",
       "..                                                ...       ...        ...   \n",
       "0   {'non-sexist': {'precision': 0.267857142857142...  0.483775   0.631415   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...  0.476382   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...  0.476382   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...  0.484414   0.623622   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...  0.484414   0.623622   \n",
       "\n",
       "    non_sexist_F1  \n",
       "0        0.838323  \n",
       "0        0.838323  \n",
       "0        0.834646  \n",
       "0        0.834646  \n",
       "0        0.806584  \n",
       "..            ...  \n",
       "0        0.336134  \n",
       "0        0.291022  \n",
       "0        0.291022  \n",
       "0        0.345205  \n",
       "0        0.345205  \n",
       "\n",
       "[328 rows x 7 columns]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "F1s = []\n",
    "in_sex = []\n",
    "in_non = []\n",
    "\n",
    "for index, row in metrics_df.iterrows():\n",
    "    F1 = dict(row[\"scores\"])[\"macro avg\"][\"f1-score\"]\n",
    "    class_sexism_f1 = dict(row[\"scores\"])[\"sexist\"][\"f1-score\"]\n",
    "    non_sex = dict(row[\"scores\"])[\"non-sexist\"][\"f1-score\"]\n",
    "    F1s.append(F1)\n",
    "    in_sex.append(class_sexism_f1)\n",
    "    in_non.append(non_sex)\n",
    "    \n",
    "#     print(F1)\n",
    "#     print(in_sex)\n",
    "\n",
    "metrics_df[\"F1\"] = F1s\n",
    "metrics_df[\"sexist_F1\"] = in_sex\n",
    "metrics_df[\"non_sexist_F1\"] = in_non\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e42f67",
   "metadata": {},
   "source": [
    "### clean data of duplicates and participants who didn't do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "380a073a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['definition', 'expert', 'dataset', 'F1', 'sexist_F1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-945409c8bd14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"definition\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sexist_F1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5782\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5841\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5842\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['definition', 'expert', 'dataset', 'F1', 'sexist_F1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "clean_data = metrics_df[metrics_df[[\"definition\", \"expert\", \"dataset\", \"F1\", \"sexist_F1\"]].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e61dac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5fb9e3c31707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpert\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"EXP_8\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpert\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"EXP_7\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_data' is not defined"
     ]
    }
   ],
   "source": [
    "clean_data = clean_data[clean_data.expert != \"EXP_8\"]\n",
    "clean_data = clean_data[clean_data.expert != \"EXP_7\"]\n",
    "clean_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
