{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "golden-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isen1\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#from revChatGPT.V2 import Chatbot\n",
    "#from revChatGPT.V2 import Conversation\n",
    "#from revChatGPT.V2 import Conversations\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reported-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ! pip install openai==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f8924-3bc8-4771-b8c5-51b832813a5f",
   "metadata": {},
   "source": [
    "### Huggingface Serverless inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c8eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install huggingface_hub==0.25.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laden-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70d3f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hf_key.json', 'r') as infile: key = json.load(infile)\n",
    "client = InferenceClient(api_key=key['hf']) # insert key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "contrary-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'finish_reason': 'stop',\n",
       "  'index': 0,\n",
       "  'message': {'role': 'assistant',\n",
       "   'content': '5\\n\\nI would rate this comment a 5, as it contains a profanity and a derogatory slur that is dehumanizing and demeaning. The language used is extremely aggressive and misogynistic, implying ownership and control over someone else, which is highly offensive and unacceptable.',\n",
       "   'tool_calls': None},\n",
       "  'logprobs': None}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for message in client.chat_completion(\n",
    "\tmodel=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "\tmessages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")\n",
    "\n",
    "content = \"comment: Fuck you, you're my bitch\"\n",
    "\n",
    "prompt = \"Consider you read the above comment on Reddit. How offensive do you think it is, on a scale from 1 (not offensive at all) to 5 (very offensive)? Valid options: 1, 2, 3, 4, 5. Begin your response by selecting one of the valid options, then provide a concise explanation for your rating.\"\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json\",\n",
    "    \"value\": {\n",
    "        \"properties\": {\n",
    "            \"rating\": {\"type\": \"string\"},\n",
    "            \"explanation\": {\"type\": \"string\"},\n",
    "        },\n",
    "        \"required\": [\"label\", \"explanation\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "response = client.chat_completion(\n",
    "\tmodel=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "\tmessages=[{\"role\": \"user\", \"content\": content + ' ' + prompt}],\n",
    "  # response_format=response_format,\n",
    "  stream=False\n",
    "\t# max_tokens=500,\n",
    "\t)\n",
    "\n",
    "response['choices']#[0]['message']['content']#.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-closer",
   "metadata": {},
   "source": [
    "## Prompt Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strong-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "## original prompt\n",
    "def create_prompt_definition_sexism(definition):\n",
    "\n",
    "    prompt = f\"Your task is to annotate if a piece of text is sexist or not.\\\n",
    "    Later, you get a detailed definition of sexism. \\\n",
    "    Definition of sexism: {definition} \"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c98bc1-b708-4bb9-b113-72703900de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text1 = \"women are capable of commentating on football matches\" \n",
    "test_text2 = \"women are weak and belong in the kitchen\"\n",
    "\n",
    "test_definition = \"sexism is when men comment on women\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09b8360-5038-4c75-b34e-ad3667b29e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt_definition_sexism(test_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d9a8c4-18e3-4ccb-a4ff-f379c07ba1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: sexism is when men comment on women '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b391c8fe-a60e-4cd8-b3da-79625b4d11b7",
   "metadata": {},
   "source": [
    "#### import definitions, put in dictionary per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65886ae0-34f9-4989-b076-fbb3cabf0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions_data = pd.read_csv(\"../../data/definitions/Sexism/Definitions_Interaction_ds - Definitions_Interaction_ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0aa6735-02b7-445e-8924-c647d511a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def_dict = defaultdict()\n",
    "\n",
    "for _, row in definitions_data.iterrows():\n",
    "    participant_dict = defaultdict()\n",
    "    participant_dict[\"chosen_definition_10\"] = row[\"chosen_definition_10\"]\n",
    "    participant_dict[\"def_ChatGPT_1\"] = row[\"def_ChatGPT_1\"]\n",
    "    participant_dict[\"participant_definition\"] = row[\"participant_define\"]\n",
    "    try: \n",
    "        participant_dict[\"definition_category\"] = row[\"Indira Definition Category\"].split(\" detail\")[0]\n",
    "    except:\n",
    "        participant_dict[\"definition_category\"] = \"unk\"\n",
    "    def_dict[row[\"ResponseId\"]] = participant_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759129e7-ad10-4730-83f1-c578562333c7",
   "metadata": {},
   "source": [
    "#### add definition prompts to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc15702e-047e-4189-8a6c-75fb98c20f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in def_dict.keys():\n",
    "    def_dict[participant][\"prompt_definition_chosen_10\"] = create_prompt_definition_sexism(def_dict[participant][\"chosen_definition_10\"])\n",
    "    def_dict[participant][\"prompt_definition_ChatGPT_1\"] = create_prompt_definition_sexism(def_dict[participant][\"def_ChatGPT_1\"])\n",
    "    def_dict[participant][\"prompt_definition_participant\"] = create_prompt_definition_sexism(def_dict[participant][\"participant_definition\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc6bccc9-db4f-4b84-b3da-aeb0b0bc0a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'EXP_1': defaultdict(None,\n",
       "                         {'chosen_definition_10': \"Sexism refers to prejudice, discrimination, or stereotyping based on a person's sex or gender, typically with a bias against one gender over the other. It can manifest in various forms, including unequal treatment, unfair expectations, and harmful attitudes or beliefs about individuals based on their sex. Examples of everyday sexism in the workplace could include paying women less than men for the same job or assuming certain roles are only suitable for one gender. Online sexism could involve making derogatory comments based on gender or perpetuating harmful stereotypes in digital spaces. \",\n",
       "                          'def_ChatGPT_1': \"Certainly! Sexism refers to prejudice, discrimination, or stereotyping based on a person's sex or gender, typically with a bias against one gender over the other. Sexism can manifest in various forms, including unequal treatment, unfair expectations, and harmful attitudes or beliefs about individuals based on their sex.\",\n",
       "                          'participant_definition': 'Sexism is discrimination based on gender, including stereotypes and prejudice. It can take many forms, from offensive language to sexual violence. ',\n",
       "                          'definition_category': 'medium',\n",
       "                          'prompt_definition_chosen_10': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism refers to prejudice, discrimination, or stereotyping based on a person's sex or gender, typically with a bias against one gender over the other. It can manifest in various forms, including unequal treatment, unfair expectations, and harmful attitudes or beliefs about individuals based on their sex. Examples of everyday sexism in the workplace could include paying women less than men for the same job or assuming certain roles are only suitable for one gender. Online sexism could involve making derogatory comments based on gender or perpetuating harmful stereotypes in digital spaces.  \",\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Certainly! Sexism refers to prejudice, discrimination, or stereotyping based on a person's sex or gender, typically with a bias against one gender over the other. Sexism can manifest in various forms, including unequal treatment, unfair expectations, and harmful attitudes or beliefs about individuals based on their sex. \",\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is discrimination based on gender, including stereotypes and prejudice. It can take many forms, from offensive language to sexual violence.  '}),\n",
       "             'EXP_2': defaultdict(None,\n",
       "                         {'chosen_definition_10': \"Sexism is a form of prejudice, stereotyping, or discrimination based on gender, often targeting women. This bias reflects the belief in one gender's superiority, resulting in unfair treatment, negative stereotypes, and limited opportunities solely due to gender. For example, a common illustration of sexism is the gender pay gap, where women are paid less than men for the same work. Sexism can manifest in different forms like unequal treatment, unfair stereotypes, or restrictions on opportunities, impacting both individuals and society. If you require more examples or details for each form of sexism, feel free to ask! Sexism's effects can be harmful, leading to inequalities, perpetuating stereotypes, and limiting opportunities for individuals. It primarily affects women but can also impact men in different contexts. Resolving sexism involves efforts at individual, societal, and institutional levels through education, promoting gender equality, implementing fair policies, and challenging discriminatory practices. If you need further clarification or details on this topic, please let me know!\",\n",
       "                          'def_ChatGPT_1': \"Sexism is prejudice, stereotyping, or discrimination, typically against women, based on their gender. It involves beliefs or attitudes that one gender is superior to another and can manifest in various forms, such as unequal treatment, unfair stereotypes, or restrictions on opportunities based on someone's gender. Sexism can occur both on an individual level and within institutional structures, and it can have negative impacts on individuals and society as a whole.\",\n",
       "                          'participant_definition': 'I would define sexism as a way to imply stereotypical or unrespectful opinion on gender.',\n",
       "                          'definition_category': 'low',\n",
       "                          'prompt_definition_chosen_10': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of prejudice, stereotyping, or discrimination based on gender, often targeting women. This bias reflects the belief in one gender's superiority, resulting in unfair treatment, negative stereotypes, and limited opportunities solely due to gender. For example, a common illustration of sexism is the gender pay gap, where women are paid less than men for the same work. Sexism can manifest in different forms like unequal treatment, unfair stereotypes, or restrictions on opportunities, impacting both individuals and society. If you require more examples or details for each form of sexism, feel free to ask! Sexism's effects can be harmful, leading to inequalities, perpetuating stereotypes, and limiting opportunities for individuals. It primarily affects women but can also impact men in different contexts. Resolving sexism involves efforts at individual, societal, and institutional levels through education, promoting gender equality, implementing fair policies, and challenging discriminatory practices. If you need further clarification or details on this topic, please let me know! \",\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is prejudice, stereotyping, or discrimination, typically against women, based on their gender. It involves beliefs or attitudes that one gender is superior to another and can manifest in various forms, such as unequal treatment, unfair stereotypes, or restrictions on opportunities based on someone's gender. Sexism can occur both on an individual level and within institutional structures, and it can have negative impacts on individuals and society as a whole. \",\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: I would define sexism as a way to imply stereotypical or unrespectful opinion on gender. '}),\n",
       "             'EXP_3': defaultdict(None,\n",
       "                         {'chosen_definition_10': \"Sexism refers to discrimination, prejudice, or stereotyping based on a person's gender. It can manifest in various forms, such as treating individuals differently because of their gender, assuming certain characteristics or behaviors based on gender, or denying opportunities to someone because of their gender. Sexism can affect people of all genders, but it is often directed towards women and can have harmful effects on their lives and opportunities. There are different types of sexism, such as hostile sexism, benevolent sexism, and ambivalent sexism.\",\n",
       "                          'def_ChatGPT_1': \"Sexism is discrimination, prejudice, or stereotyping based on a person's gender. It can manifest in various forms, such as treating individuals differently because of their gender, assuming certain characteristics or behaviors based on gender, or denying opportunities to someone because of their gender. Sexism can affect people of all genders, but it is often directed towards women and can have harmful effects on their lives and opportunities.\",\n",
       "                          'participant_definition': 'Believing that one sex is superior to another. It includes different forms of harmful stereotyping including benevolent sexism, etc.',\n",
       "                          'definition_category': 'medium',\n",
       "                          'prompt_definition_chosen_10': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism refers to discrimination, prejudice, or stereotyping based on a person's gender. It can manifest in various forms, such as treating individuals differently because of their gender, assuming certain characteristics or behaviors based on gender, or denying opportunities to someone because of their gender. Sexism can affect people of all genders, but it is often directed towards women and can have harmful effects on their lives and opportunities. There are different types of sexism, such as hostile sexism, benevolent sexism, and ambivalent sexism. \",\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is discrimination, prejudice, or stereotyping based on a person's gender. It can manifest in various forms, such as treating individuals differently because of their gender, assuming certain characteristics or behaviors based on gender, or denying opportunities to someone because of their gender. Sexism can affect people of all genders, but it is often directed towards women and can have harmful effects on their lives and opportunities. \",\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Believing that one sex is superior to another. It includes different forms of harmful stereotyping including benevolent sexism, etc. '}),\n",
       "             'EXP_4': defaultdict(None,\n",
       "                         {'chosen_definition_10': \"It's fascinating to see your expertise in discerning subtle linguistic cues to identify sexism in texts. The definition of sexism centers on discrimination, prejudice, stereotyping, and biased behaviors toward individuals based on gender, leading to unequal treatment and marginalization. Evaluating texts for sexism entails examining portrayals of gender superiority or inferiority, reinforcement of stereotypes, and gender-based limitations, which involves analyzing the text's structure, tone, and phrasing to ascertain if it perpetuates gender inequality. \",\n",
       "                          'def_ChatGPT_1': \"Sexism is a form of discrimination, prejudice, or stereotyping based on a person's gender. It involves attitudes, beliefs, and behaviors that differentiate, marginalize, or treat individuals differently based on their gender. Sexism can manifest in various ways, such as through language, actions, or systemic biases that perpetuate inequality between genders. When analyzing a text for sexism, I assess if it portrays one gender as superior or inferior to the other, reinforces harmful stereotypes, or limits an individual's opportunities or worth based on their gender.\",\n",
       "                          'participant_definition': 'A prescriptive set of behaviors or qualities, that women (and men) are supposed to exhibit to conform to traditional gender roles.  \\n',\n",
       "                          'definition_category': 'medium',\n",
       "                          'prompt_definition_chosen_10': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: It's fascinating to see your expertise in discerning subtle linguistic cues to identify sexism in texts. The definition of sexism centers on discrimination, prejudice, stereotyping, and biased behaviors toward individuals based on gender, leading to unequal treatment and marginalization. Evaluating texts for sexism entails examining portrayals of gender superiority or inferiority, reinforcement of stereotypes, and gender-based limitations, which involves analyzing the text's structure, tone, and phrasing to ascertain if it perpetuates gender inequality.  \",\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of discrimination, prejudice, or stereotyping based on a person's gender. It involves attitudes, beliefs, and behaviors that differentiate, marginalize, or treat individuals differently based on their gender. Sexism can manifest in various ways, such as through language, actions, or systemic biases that perpetuate inequality between genders. When analyzing a text for sexism, I assess if it portrays one gender as superior or inferior to the other, reinforces harmful stereotypes, or limits an individual's opportunities or worth based on their gender. \",\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: A prescriptive set of behaviors or qualities, that women (and men) are supposed to exhibit to conform to traditional gender roles.  \\n '}),\n",
       "             'EXP_5': defaultdict(None,\n",
       "                         {'chosen_definition_10': 'Sexism specifically refers to discrimination, prejudice, or stereotyping directed towards individuals or groups based on their gender, where gender is the underlying cause of the abusive behavior. Mentioning the gender of the target alone may not be sufficient for a sentence to be considered sexist. Your task is to help identify and address harmful and unfair attitudes and behaviors towards people because of their gender, while also recognizing that counter speech to challenge these harmful attitudes is permissible.',\n",
       "                          'def_ChatGPT_1': 'Sure! Here\\'s a suitable prompt for the LLM:\\n\\n\"Given a piece of text, please analyze and identify any instances of sexism present.\"\\n\\nSexism refers to discrimination, prejudice, or stereotyping based on a person\\'s gender. It can manifest in various forms, such as unequal treatment, biased portrayals, or derogatory language targeting individuals or groups based on their gender. The goal of detecting sexism using a language model is to help identify and address harmful and unfair attitudes and behaviors towards people because of their gender.',\n",
       "                          'participant_definition': 'Abusive language targeted to an individual or group because of their sex and/or gender.',\n",
       "                          'definition_category': 'medium',\n",
       "                          'prompt_definition_chosen_10': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism specifically refers to discrimination, prejudice, or stereotyping directed towards individuals or groups based on their gender, where gender is the underlying cause of the abusive behavior. Mentioning the gender of the target alone may not be sufficient for a sentence to be considered sexist. Your task is to help identify and address harmful and unfair attitudes and behaviors towards people because of their gender, while also recognizing that counter speech to challenge these harmful attitudes is permissible. ',\n",
       "                          'prompt_definition_ChatGPT_1': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sure! Here\\'s a suitable prompt for the LLM:\\n\\n\"Given a piece of text, please analyze and identify any instances of sexism present.\"\\n\\nSexism refers to discrimination, prejudice, or stereotyping based on a person\\'s gender. It can manifest in various forms, such as unequal treatment, biased portrayals, or derogatory language targeting individuals or groups based on their gender. The goal of detecting sexism using a language model is to help identify and address harmful and unfair attitudes and behaviors towards people because of their gender. ',\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Abusive language targeted to an individual or group because of their sex and/or gender. '}),\n",
       "             'EXP_6': defaultdict(None,\n",
       "                         {'chosen_definition_10': \"Hostile sexism refers to overtly negative and hostile attitudes and behaviors towards women based on the belief that women are inferior to men. This can involve open discrimination, derogatory remarks, and devaluation of women. Benevolent sexism, on the other hand, involves attitudes and behaviors that may appear positive or chivalrous on the surface, but actually serve to reinforce traditional gender roles and keep women in subordinate positions. These attitudes often arise from the societal norms and expectations that distinguish men and women based on their perceived social roles and characteristics. Examples of benevolent sexism include patronizing behavior, protective gestures, or idealizing women as pure and delicate. To detect sexism in text, look for language or scenarios that suggest unequal treatment, devaluation, or reinforcement of traditional gender roles. Pay attention to how women are portrayed, whether they are being reduced to stereotypes, denied agency, or discriminated against. Both hostile and benevolent sexism can manifest in various ways in written content, so it's important to analyze the overall context and underlying messages being conveyed.\",\n",
       "                          'def_ChatGPT_1': \"Hostile sexism refers to overtly negative and hostile attitudes and behaviors towards women based on the belief that women are inferior to men. This can involve open discrimination, derogatory remarks, and devaluation of women.\\n\\nBenevolent sexism, on the other hand, involves attitudes and behaviors that may appear positive or chivalrous on the surface, but actually serve to reinforce traditional gender roles and keep women in subordinate positions. Examples of benevolent sexism include patronizing behavior, protective gestures, or idealizing women as pure and delicate.\\n\\nTo detect sexism in text, look for language or scenarios that suggest unequal treatment, devaluation, or reinforcement of traditional gender roles. Pay attention to how women are portrayed, whether they are being reduced to stereotypes, denied agency, or discriminated against. Both hostile and benevolent sexism can manifest in different ways in written content, so it's important to analyze the overall context and underlying messages being conveyed.\",\n",
       "                          'participant_definition': 'Statements or behaviours that reinforce the idea that men are given more power and status than women, that men and women are (or should be) distinguished on the basis of their social roles and characteristics; and relationships between men and women are defined by sexual reproduction and intimacy. Sexism can take the form of hostile and benevolent sexism.',\n",
       "                          'definition_category': 'multidimensional,high',\n",
       "                          'prompt_definition_chosen_10': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Hostile sexism refers to overtly negative and hostile attitudes and behaviors towards women based on the belief that women are inferior to men. This can involve open discrimination, derogatory remarks, and devaluation of women. Benevolent sexism, on the other hand, involves attitudes and behaviors that may appear positive or chivalrous on the surface, but actually serve to reinforce traditional gender roles and keep women in subordinate positions. These attitudes often arise from the societal norms and expectations that distinguish men and women based on their perceived social roles and characteristics. Examples of benevolent sexism include patronizing behavior, protective gestures, or idealizing women as pure and delicate. To detect sexism in text, look for language or scenarios that suggest unequal treatment, devaluation, or reinforcement of traditional gender roles. Pay attention to how women are portrayed, whether they are being reduced to stereotypes, denied agency, or discriminated against. Both hostile and benevolent sexism can manifest in various ways in written content, so it's important to analyze the overall context and underlying messages being conveyed. \",\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Hostile sexism refers to overtly negative and hostile attitudes and behaviors towards women based on the belief that women are inferior to men. This can involve open discrimination, derogatory remarks, and devaluation of women.\\n\\nBenevolent sexism, on the other hand, involves attitudes and behaviors that may appear positive or chivalrous on the surface, but actually serve to reinforce traditional gender roles and keep women in subordinate positions. Examples of benevolent sexism include patronizing behavior, protective gestures, or idealizing women as pure and delicate.\\n\\nTo detect sexism in text, look for language or scenarios that suggest unequal treatment, devaluation, or reinforcement of traditional gender roles. Pay attention to how women are portrayed, whether they are being reduced to stereotypes, denied agency, or discriminated against. Both hostile and benevolent sexism can manifest in different ways in written content, so it's important to analyze the overall context and underlying messages being conveyed. \",\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Statements or behaviours that reinforce the idea that men are given more power and status than women, that men and women are (or should be) distinguished on the basis of their social roles and characteristics; and relationships between men and women are defined by sexual reproduction and intimacy. Sexism can take the form of hostile and benevolent sexism. '}),\n",
       "             'EXP_7': defaultdict(None,\n",
       "                         {'chosen_definition_10': nan,\n",
       "                          'def_ChatGPT_1': nan,\n",
       "                          'participant_definition': nan,\n",
       "                          'definition_category': 'unk',\n",
       "                          'prompt_definition_chosen_10': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: nan ',\n",
       "                          'prompt_definition_ChatGPT_1': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: nan ',\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: nan '}),\n",
       "             'EXP_8': defaultdict(None,\n",
       "                         {'chosen_definition_10': nan,\n",
       "                          'def_ChatGPT_1': nan,\n",
       "                          'participant_definition': nan,\n",
       "                          'definition_category': 'unk',\n",
       "                          'prompt_definition_chosen_10': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: nan ',\n",
       "                          'prompt_definition_ChatGPT_1': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: nan ',\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: nan '}),\n",
       "             'EXP_9': defaultdict(None,\n",
       "                         {'chosen_definition_10': \"Sexism is a form of discrimination, prejudice, or stereotyping based on a person's sex or gender, typically towards women or girls. It involves treating people differently or unfairly because of their gender, and can be expressed in various forms, such as unequal treatment, stereotypes, or systemic sexism within societal structures.\",\n",
       "                          'def_ChatGPT_1': \"Sexism is a form of discrimination, prejudice, or stereotyping based on a person's sex or gender, typically towards women or girls. It involves treating individuals differently or unfairly because of their gender, and can be expressed in various forms, such as unequal treatment, stereotypes, or systemic sexism within societal structures.\",\n",
       "                          'participant_definition': 'Sexism is linked to beliefs around the fundamental nature of women and men and the roles they should play in society. Sexist assumptions about women and men, which manifest themselves as gender stereotypes, can rank one gender as superior to another.',\n",
       "                          'definition_category': 'high',\n",
       "                          'prompt_definition_chosen_10': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of discrimination, prejudice, or stereotyping based on a person's sex or gender, typically towards women or girls. It involves treating people differently or unfairly because of their gender, and can be expressed in various forms, such as unequal treatment, stereotypes, or systemic sexism within societal structures. \",\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of discrimination, prejudice, or stereotyping based on a person's sex or gender, typically towards women or girls. It involves treating individuals differently or unfairly because of their gender, and can be expressed in various forms, such as unequal treatment, stereotypes, or systemic sexism within societal structures. \",\n",
       "                          'prompt_definition_participant': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is linked to beliefs around the fundamental nature of women and men and the roles they should play in society. Sexist assumptions about women and men, which manifest themselves as gender stereotypes, can rank one gender as superior to another. '}),\n",
       "             'EXP_10': defaultdict(None,\n",
       "                         {'chosen_definition_10': 'Sexism is the manifestation of discriminatory, prejudiced, or stereotypical attitudes towards individuals based on their sex or gender. Understanding sexism includes recognizing and addressing the systemic, structural components deeply ingrained in societal norms, practices, and institutions that perpetuate unequal treatment and opportunities among genders. Understanding the power dynamics and societal frameworks that fuel gender inequality in diverse contexts is crucial for combating sexism effectively.\\n ',\n",
       "                          'def_ChatGPT_1': \"Sexism is a form of discrimination, prejudice, or stereotyping based on a person's sex or gender, typically against women and girls. It involves treating individuals differently or unfairly because of their sex or gender, and often involves the belief that one gender is superior to another.\",\n",
       "                          'participant_definition': \"Broadly, sexism is prejudice or discrimination based on one's sex or gender - a form of oppression that results primarily in disadvantages for women and queer people.\\nA more technical definition of sexism is a system of norms, beliefs, and practices that normalise, perpetuate, and legitimise a binary, heteronormative, and/or deterministic framework of understanding sex and gender. Sexism can manifest in many different ways and it is deeply embedded in our institutions, practices, traditions, cultural norms and values. So detecting and understanding how sexism works necessarily involves studying how society is structured, organised, and governed.\",\n",
       "                          'definition_category': 'high',\n",
       "                          'prompt_definition_chosen_10': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is the manifestation of discriminatory, prejudiced, or stereotypical attitudes towards individuals based on their sex or gender. Understanding sexism includes recognizing and addressing the systemic, structural components deeply ingrained in societal norms, practices, and institutions that perpetuate unequal treatment and opportunities among genders. Understanding the power dynamics and societal frameworks that fuel gender inequality in diverse contexts is crucial for combating sexism effectively.\\n  ',\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of discrimination, prejudice, or stereotyping based on a person's sex or gender, typically against women and girls. It involves treating individuals differently or unfairly because of their sex or gender, and often involves the belief that one gender is superior to another. \",\n",
       "                          'prompt_definition_participant': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Broadly, sexism is prejudice or discrimination based on one's sex or gender - a form of oppression that results primarily in disadvantages for women and queer people.\\nA more technical definition of sexism is a system of norms, beliefs, and practices that normalise, perpetuate, and legitimise a binary, heteronormative, and/or deterministic framework of understanding sex and gender. Sexism can manifest in many different ways and it is deeply embedded in our institutions, practices, traditions, cultural norms and values. So detecting and understanding how sexism works necessarily involves studying how society is structured, organised, and governed. \"}),\n",
       "             'EXP_11': defaultdict(None,\n",
       "                         {'chosen_definition_10': 'Sexism is a form of prejudice or discrimination based on a person\\'s sex or gender, typically against women but also impacting men. Discrimination can manifest in various ways, including unequal treatment, stereotypes, or demeaning attitudes towards individuals based on their gender. Positive stereotypes, even if seemingly complimentary, can still contribute to sexism by reinforcing harmful beliefs about certain genders. An example of a positive stereotype that is harmful is the belief that women are naturally more nurturing and caring than men, which can limit opportunities for women by prioritizing caregiving roles over personal and professional aspirations. In response to your question about whether the statement that \"women are stronger than men since they can sustain labor pains, whose intensity is known to be one of the worst kinds of pain known to humans\" is sexist, the emphasis on labor pain as a defining strength can perpetuate stereotypes and reinforce traditional gender roles. It restricts the recognition of other diverse strengths individuals possess, which ultimately contributes to the reinforcement of gender norms and inequality. To make the sentence non-sexist, it could be rephrased to acknowledge various strengths and abilities without attributing them solely to gender, promoting inclusivity and respect for individual differences. If you would like more examples of cases that might not be overtly sexist but still have a sexist undertone, please let me know.',\n",
       "                          'def_ChatGPT_1': \"Sexism is a form of prejudice or discrimination based on a person's sex or gender, typically against women but also impacting men. This discrimination can manifest in various ways, such as unequal treatment, stereotypes, or demeaning attitudes towards individuals based on their gender.\",\n",
       "                          'participant_definition': \"A view of an identity that is defined by social beliefs but is not necessarily supported by a ground truth or doesn't reflect their actual abilities\",\n",
       "                          'definition_category': 'low',\n",
       "                          'prompt_definition_chosen_10': 'Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of prejudice or discrimination based on a person\\'s sex or gender, typically against women but also impacting men. Discrimination can manifest in various ways, including unequal treatment, stereotypes, or demeaning attitudes towards individuals based on their gender. Positive stereotypes, even if seemingly complimentary, can still contribute to sexism by reinforcing harmful beliefs about certain genders. An example of a positive stereotype that is harmful is the belief that women are naturally more nurturing and caring than men, which can limit opportunities for women by prioritizing caregiving roles over personal and professional aspirations. In response to your question about whether the statement that \"women are stronger than men since they can sustain labor pains, whose intensity is known to be one of the worst kinds of pain known to humans\" is sexist, the emphasis on labor pain as a defining strength can perpetuate stereotypes and reinforce traditional gender roles. It restricts the recognition of other diverse strengths individuals possess, which ultimately contributes to the reinforcement of gender norms and inequality. To make the sentence non-sexist, it could be rephrased to acknowledge various strengths and abilities without attributing them solely to gender, promoting inclusivity and respect for individual differences. If you would like more examples of cases that might not be overtly sexist but still have a sexist undertone, please let me know. ',\n",
       "                          'prompt_definition_ChatGPT_1': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: Sexism is a form of prejudice or discrimination based on a person's sex or gender, typically against women but also impacting men. This discrimination can manifest in various ways, such as unequal treatment, stereotypes, or demeaning attitudes towards individuals based on their gender. \",\n",
       "                          'prompt_definition_participant': \"Your task is to annotate if a piece of text is sexist or not.    Later, you get a detailed definition of sexism.     Definition of sexism: A view of an identity that is defined by social beliefs but is not necessarily supported by a ground truth or doesn't reflect their actual abilities \"})})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38c712-a820-4dce-9220-f4bb09261d9d",
   "metadata": {},
   "source": [
    "#### Add texts to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6d85a3-bbb6-45e5-8208-a815e495d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_texts_to_prompts(prompt_dict, prompt_version, text):\n",
    "    preamble = prompt_dict[prompt_version]\n",
    "    prompt = preamble + f\"With this definition in mind and a piece of text, please reply with either of the three options and nothing else: 1) sexist, 2) non-sexist, 3) can’t say. Please use the last option as little as possible and if you do, provide a one sentence explanation. Do not give an explanation if you pick ’sexist’ or ’non-sexist’. \\\n",
    "    We are ready to begin now. Is this sentence sexist based on the past definition’ : {text} - ’Please reply with either of the three options and nothing else: 1) sexist, 2) non-sexist, 3) can’t say.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37131edc-b147-40c7-a802-595405e8ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760c390-1fc0-43dc-8cbb-dde912ac9ff5",
   "metadata": {},
   "source": [
    "### Classification test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44489cc8-d973-408b-b072-d9eb31446f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = add_texts_to_prompts(participant_dict, \n",
    "                             \"prompt_definition_participant\", \n",
    "                            \"Girls are dumber than boys\")\n",
    "\n",
    "response = client.chat_completion(\n",
    "\tmodel=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "\tmessages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  # response_format=response_format,\n",
    "  stream=False\n",
    "\t# max_tokens=500,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff362f0-716b-4b0c-bda2-81073586b41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'finish_reason': 'stop',\n",
       "  'index': 0,\n",
       "  'message': {'role': 'assistant', 'content': '1) sexist', 'tool_calls': None},\n",
       "  'logprobs': None}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices']#[0]['message']['content']#.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dict_of_dfs_LLaMa.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443df79-b840-432d-8619-7470c56cbae2",
   "metadata": {},
   "source": [
    "### Data to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7617114b-cb25-46f7-bc23-45e0db48728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = ['in_domain', 'out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3',# 'out_of_domain_4', \n",
    "             'hatecheck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c53e6369-1ded-49a8-9508-75d0283fa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_names = ['sexism']\n",
    "\n",
    "construct = 'sexism'\n",
    "pos_label = 'sexist'\n",
    "neg_label = 'non-sexist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae179e84-fbcd-4c6f-8f06-0b6de55bdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "\n",
    "#test with 10, remove head(10) to test on all data\n",
    "\n",
    "for construct in construct_names:\n",
    "    test_set_data[construct] = {}\n",
    "    for test_set in test_sets:\n",
    "        test_path = '../../data/data/%s/test/%s.csv' %(construct, test_set)\n",
    "        test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t').sample(n=500, random_state=123).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "025e748e-b8c1-44e4-9500-49e97eba8102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_domain':                            _id  \\\n",
       " 701   5d654927ce2c6bd733479677   \n",
       " 186   5d654920ce2c6bd733478932   \n",
       " 13    5d654922ce2c6bd733478daa   \n",
       " 1134  5d65490ece2c6bd733476c25   \n",
       " 1165  5d65491ace2c6bd733477eda   \n",
       " 45    5d65491ace2c6bd733477e64   \n",
       " 643   5d654924ce2c6bd73347955d   \n",
       " 1177  5d6eafdf0fde4e38fac33a1e   \n",
       " 1084  5d654923ce2c6bd7334792ae   \n",
       " 709   5d654921ce2c6bd733478bfe   \n",
       " \n",
       "                                                    text      sexism  \n",
       " 701   don’t they all look the same without makeup 💄?...  non-sexist  \n",
       " 186   I really don't think Brides Magazine belongs i...  non-sexist  \n",
       " 13    99% of the women I reach out to as sources ben...  non-sexist  \n",
       " 1134  Guy whose car we blocked in high-fiving marche...  non-sexist  \n",
       " 1165  When her hands get sore, she finds another way...  non-sexist  \n",
       " 45                @pondereroftruth @sara771987 Perhaps.  non-sexist  \n",
       " 643   @RikSennin @lizzyf620 you actually believe tha...  non-sexist  \n",
       " 1177  I accept that in my circle of friends, my part...      sexist  \n",
       " 1084  And you all can I am uncomfortable with women ...      sexist  \n",
       " 709   I am so sick of men being excused from the con...  non-sexist  ,\n",
       " 'out_of_domain':        _id                                               text      sexism\n",
       " 2464  2465  Women will hit the curb and be like “oops” htt...      sexist\n",
       " 649    650  @ZoryaStar @Freezurn This also goes into a bro...      sexist\n",
       " 866    867  @jaydarcy7 @pete_hennessy Misses the point. He...      sexist\n",
       " 2672  2673                    @theboysmum1 Agreed. #NotAllMen  non-sexist\n",
       " 2448  2449  @Liftandcarryguy @nicegirlmeg I’m not insultin...      sexist\n",
       " 2895  2896  This is great!!|Two woman wearying tights span...      sexist\n",
       " 471    472  He doesn't know what rape means sbut he'll do ...      sexist\n",
       " 1373  1374  @KuboS0S Hope your doing better now, I feel ya...  non-sexist\n",
       " 773    774  Aye bro if you had a gold digger just say that...      sexist\n",
       " 2581  2582  @dudiegirl2 @RepPaulMitchell No one is referri...  non-sexist,\n",
       " 'out_of_domain_2':                _id                                               text  \\\n",
       " 5890  fqoqfty_5900  > More specifically, yes, men are and were in ...   \n",
       " 3122   g62zqj_3128  WHAT WOMEN WANT>\"After 30 years of studying fe...   \n",
       " 1617  fj5t4ue_1620  Actually, the movie flash point has a female j...   \n",
       " 5541  fpoujw3_5551  IDK in my experience all girls are submissive ...   \n",
       " 4796  fpnv1m5_4805  Use to happen to me all the time. I don't both...   \n",
       " 5426  fq1vwr4_5436  tiktok cringe is just ugly people doing all th...   \n",
       " 5781  fr1cvz0_5791  I think you should do what makes you feel good...   \n",
       " 1462  fis0xqr_1465                             Holy shit. I know her!   \n",
       " 1673  fk383gu_1676  Yeah, I hate old men with high standards. Old ...   \n",
       " 2636  fk3eojf_2640  We're writing a simple guide for exactly this ...   \n",
       " \n",
       "           sexism  \n",
       " 5890  non-sexist  \n",
       " 3122      sexist  \n",
       " 1617  non-sexist  \n",
       " 5541  non-sexist  \n",
       " 4796  non-sexist  \n",
       " 5426  non-sexist  \n",
       " 5781  non-sexist  \n",
       " 1462  non-sexist  \n",
       " 1673  non-sexist  \n",
       " 2636  non-sexist  ,\n",
       " 'out_of_domain_3':                             _id  \\\n",
       " 12136  sexism2022_english-17429   \n",
       " 16812  sexism2022_english-13648   \n",
       " 10072  sexism2022_english-12656   \n",
       " 5850    sexism2022_english-7759   \n",
       " 4320    sexism2022_english-2319   \n",
       " 4429    sexism2022_english-8852   \n",
       " 11744   sexism2022_english-2435   \n",
       " 12106  sexism2022_english-18073   \n",
       " 4230    sexism2022_english-6460   \n",
       " 16858    sexism2022_english-939   \n",
       " \n",
       "                                                     text      sexism  \n",
       " 12136  She's already whiter than most actual whites I...  non-sexist  \n",
       " 16812  Yeah, talking shit behind your back is a big n...  non-sexist  \n",
       " 10072  LOL GTFO of here with that normie shit. Don't ...  non-sexist  \n",
       " 5850   Lady Justice carries a sword. Take away the sw...  non-sexist  \n",
       " 4320   If you've never actually got dressed, got in y...  non-sexist  \n",
       " 4429       How bout we feed her tongue to the pigs first      sexist  \n",
       " 11744  The tactics of the #TRUEENEMY is to bring hate...  non-sexist  \n",
       " 12106  Oh, my bad. This is definitely Meg Ryan. You c...  non-sexist  \n",
       " 4230                    I did not find her funny at all.  non-sexist  \n",
       " 16858  lol a friend of mine and her brother used to u...  non-sexist  ,\n",
       " 'hatecheck':       _id                                               text      sexism\n",
       " 5      36           Disgusted by all the women around here.       sexist\n",
       " 277  2009                  What if we just killed all women?      sexist\n",
       " 85    596               I'm going to stab a woman tomorrow.       sexist\n",
       " 272  1974     Isn't it typical of a woman to be that stupid?      sexist\n",
       " 318  2317            There are very few women at my school.   non-sexist\n",
       " 498  3834                      You are nothing but a b1tch.       sexist\n",
       " 148  1046       I keep two garden hoes out in my tool shed.   non-sexist\n",
       " 425  3306                             Womn belong in a zoo.       sexist\n",
       " 384  2791  It hurts to see all these people saying female...  non-sexist\n",
       " 48    337                          Women are lesser beings.       sexist}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data[\"sexism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab1f6989-bb6e-47a2-b370-49393c832c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv(\"../../data/data/sexism/train/data_sample.tsv\",  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39f8f102-7d90-45cf-b498-717adf0096da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sexism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d654925ce2c6bd7334795bd</td>\n",
       "      <td>i can't take girls serious when talk about sports</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d654901ce2c6bd733475c03</td>\n",
       "      <td>#womensday  Women have surely outdone men if t...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d65490ace2c6bd7334763c0</td>\n",
       "      <td>You've undercooked eggs and probably poisoned ...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf5d5</td>\n",
       "      <td>A daughter in a family should have the same pr...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d654921ce2c6bd733478ac5</td>\n",
       "      <td>a womans place IS the kitchen</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5d654915ce2c6bd73347758e</td>\n",
       "      <td>@dleemand \"can't take compliments\" = \"don't wa...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5d654922ce2c6bd733478fbb</td>\n",
       "      <td>I think it's cool having women working at #hom...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5d654921ce2c6bd733478c8c</td>\n",
       "      <td>girls sports are just not good</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5d65491fce2c6bd733478722</td>\n",
       "      <td>Not sexist...But I cant have a woman discussin...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5d654904ce2c6bd733475d13</td>\n",
       "      <td>ppl always discredit Mingyus height but im tal...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf6b9</td>\n",
       "      <td>I think that men are instinctually more compet...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf5a3</td>\n",
       "      <td>Retention by a wife of her maiden name is self...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5d654904ce2c6bd733475dde</td>\n",
       "      <td>Celebrate #internationalwomensday Tag the wome...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf591</td>\n",
       "      <td>Women should have the same sexual freedom as men.</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5d654923ce2c6bd733479214</td>\n",
       "      <td>Hayi fuck it nyaniRT @ClixWell: Women's 7s rug...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf7f5</td>\n",
       "      <td>Intense emotional expressiveness should not be...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5d654906ce2c6bd733475e48</td>\n",
       "      <td>I fucking wish I was a rattlesnake http://t.co...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5d654924ce2c6bd73347952b</td>\n",
       "      <td>Girls always jokes on them I've never had sex ...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5d6eafdf0fde4e38fac33a26</td>\n",
       "      <td>Many women are actually seeking special favors...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5d65490cce2c6bd73347693c</td>\n",
       "      <td>@aninkyaffair I am jealous.</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5d654923ce2c6bd7334793c8</td>\n",
       "      <td>I think Secret of Mana got this one wrong. htt...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5d65491ece2c6bd7334784af</td>\n",
       "      <td>RT @JApple8 None of the girls should have worn...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf680</td>\n",
       "      <td>The role of teaching in the elementary schools...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5d654921ce2c6bd733478ca3</td>\n",
       "      <td>Women at #Augusta is stupid. that is a traditi...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5d654926ce2c6bd7334795ff</td>\n",
       "      <td>RT @RachZoss I cannot listen to this woman com...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5d654904ce2c6bd733475d2f</td>\n",
       "      <td>#ScienceFiction would be unrecognizable withou...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5d654922ce2c6bd733478e73</td>\n",
       "      <td>women shouldn't drive transit vans!!!</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5d654923ce2c6bd73347935c</td>\n",
       "      <td>@lsg1 terrible...chicks don't belong in the bo...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf741</td>\n",
       "      <td>The ideal marriage is one in which the husband...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5d654904ce2c6bd733475d3e</td>\n",
       "      <td>Every man needs a woman when his life is a mes...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5d654904ce2c6bd733475d53</td>\n",
       "      <td>ABCDEFG means  A Boy Can Do Everything For a G...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf62a</td>\n",
       "      <td>Although there are exceptions, nagging and dom...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5d654922ce2c6bd733478e72</td>\n",
       "      <td>The left would anyone with a brain could tell ...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5d65491ece2c6bd7334783c9</td>\n",
       "      <td>Oh, I have one too!!!  @MT8_9 @HisFeministMama...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5d654923ce2c6bd7334793c2</td>\n",
       "      <td>@Anjie2006 I preferred Marilyn mornings.   Hiy...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5d654919ce2c6bd733477d6a</td>\n",
       "      <td>@shacks2cents @JustLaurenB It's actually two s...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5d654926ce2c6bd733479627</td>\n",
       "      <td>female wrestling is as exciting as watching gr...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5d654923ce2c6bd733479180</td>\n",
       "      <td>RT Clairelouo: piersmorgan I am a housewife an...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5d654921ce2c6bd733478b36</td>\n",
       "      <td>\"@LaHurston1: a girl on the phone while drivin...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5d65491ace2c6bd733477d7f</td>\n",
       "      <td>Sucks to have the smile wiped off your own fac...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5d654910ce2c6bd733477092</td>\n",
       "      <td>#mkr I think Colin might not be a fan of the m...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5d654923ce2c6bd733479338</td>\n",
       "      <td>@PeterWallaceAU @kimbakit its a very good poin...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf84e</td>\n",
       "      <td>A man should be able to openly show affection ...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5d654921ce2c6bd733478c64</td>\n",
       "      <td>@WorldOfStu @BadtotheBohn @bbarber67 @glennbec...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf6ab</td>\n",
       "      <td>Women should be prepared to oppose men in orde...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf599</td>\n",
       "      <td>The influx of women into the business world in...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf6c3</td>\n",
       "      <td>Women are inferior to men in their cognitive a...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5d654902ce2c6bd733475c6a</td>\n",
       "      <td>Women weren't created to do the things men can...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5d654925ce2c6bd7334795d5</td>\n",
       "      <td>I'm not a huge fan of woman singers (I dare yo...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5d654928ce2c6bd7334797b0</td>\n",
       "      <td>Women seek to gain power by getting control ov...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id  \\\n",
       "0   5d654925ce2c6bd7334795bd   \n",
       "1   5d654901ce2c6bd733475c03   \n",
       "2   5d65490ace2c6bd7334763c0   \n",
       "3   5ddc4fe8174b03a4c6aaf5d5   \n",
       "4   5d654921ce2c6bd733478ac5   \n",
       "5   5d654915ce2c6bd73347758e   \n",
       "6   5d654922ce2c6bd733478fbb   \n",
       "7   5d654921ce2c6bd733478c8c   \n",
       "8   5d65491fce2c6bd733478722   \n",
       "9   5d654904ce2c6bd733475d13   \n",
       "10  5ddc4fe8174b03a4c6aaf6b9   \n",
       "11  5ddc4fe8174b03a4c6aaf5a3   \n",
       "12  5d654904ce2c6bd733475dde   \n",
       "13  5ddc4fe8174b03a4c6aaf591   \n",
       "14  5d654923ce2c6bd733479214   \n",
       "15  5ddc4fe8174b03a4c6aaf7f5   \n",
       "16  5d654906ce2c6bd733475e48   \n",
       "17  5d654924ce2c6bd73347952b   \n",
       "18  5d6eafdf0fde4e38fac33a26   \n",
       "19  5d65490cce2c6bd73347693c   \n",
       "20  5d654923ce2c6bd7334793c8   \n",
       "21  5d65491ece2c6bd7334784af   \n",
       "22  5ddc4fe8174b03a4c6aaf680   \n",
       "23  5d654921ce2c6bd733478ca3   \n",
       "24  5d654926ce2c6bd7334795ff   \n",
       "25  5d654904ce2c6bd733475d2f   \n",
       "26  5d654922ce2c6bd733478e73   \n",
       "27  5d654923ce2c6bd73347935c   \n",
       "28  5ddc4fe8174b03a4c6aaf741   \n",
       "29  5d654904ce2c6bd733475d3e   \n",
       "30  5d654904ce2c6bd733475d53   \n",
       "31  5ddc4fe8174b03a4c6aaf62a   \n",
       "32  5d654922ce2c6bd733478e72   \n",
       "33  5d65491ece2c6bd7334783c9   \n",
       "34  5d654923ce2c6bd7334793c2   \n",
       "35  5d654919ce2c6bd733477d6a   \n",
       "36  5d654926ce2c6bd733479627   \n",
       "37  5d654923ce2c6bd733479180   \n",
       "38  5d654921ce2c6bd733478b36   \n",
       "39  5d65491ace2c6bd733477d7f   \n",
       "40  5d654910ce2c6bd733477092   \n",
       "41  5d654923ce2c6bd733479338   \n",
       "42  5ddc4fe8174b03a4c6aaf84e   \n",
       "43  5d654921ce2c6bd733478c64   \n",
       "44  5ddc4fe8174b03a4c6aaf6ab   \n",
       "45  5ddc4fe8174b03a4c6aaf599   \n",
       "46  5ddc4fe8174b03a4c6aaf6c3   \n",
       "47  5d654902ce2c6bd733475c6a   \n",
       "48  5d654925ce2c6bd7334795d5   \n",
       "49  5d654928ce2c6bd7334797b0   \n",
       "\n",
       "                                                 text      sexism  \n",
       "0   i can't take girls serious when talk about sports      sexist  \n",
       "1   #womensday  Women have surely outdone men if t...      sexist  \n",
       "2   You've undercooked eggs and probably poisoned ...  non-sexist  \n",
       "3   A daughter in a family should have the same pr...  non-sexist  \n",
       "4                       a womans place IS the kitchen      sexist  \n",
       "5   @dleemand \"can't take compliments\" = \"don't wa...  non-sexist  \n",
       "6   I think it's cool having women working at #hom...  non-sexist  \n",
       "7                      girls sports are just not good      sexist  \n",
       "8   Not sexist...But I cant have a woman discussin...      sexist  \n",
       "9   ppl always discredit Mingyus height but im tal...      sexist  \n",
       "10  I think that men are instinctually more compet...      sexist  \n",
       "11  Retention by a wife of her maiden name is self...      sexist  \n",
       "12  Celebrate #internationalwomensday Tag the wome...  non-sexist  \n",
       "13  Women should have the same sexual freedom as men.  non-sexist  \n",
       "14  Hayi fuck it nyaniRT @ClixWell: Women's 7s rug...      sexist  \n",
       "15  Intense emotional expressiveness should not be...      sexist  \n",
       "16  I fucking wish I was a rattlesnake http://t.co...  non-sexist  \n",
       "17  Girls always jokes on them I've never had sex ...  non-sexist  \n",
       "18  Many women are actually seeking special favors...      sexist  \n",
       "19                        @aninkyaffair I am jealous.  non-sexist  \n",
       "20  I think Secret of Mana got this one wrong. htt...  non-sexist  \n",
       "21  RT @JApple8 None of the girls should have worn...      sexist  \n",
       "22  The role of teaching in the elementary schools...      sexist  \n",
       "23  Women at #Augusta is stupid. that is a traditi...      sexist  \n",
       "24  RT @RachZoss I cannot listen to this woman com...      sexist  \n",
       "25  #ScienceFiction would be unrecognizable withou...  non-sexist  \n",
       "26              women shouldn't drive transit vans!!!      sexist  \n",
       "27  @lsg1 terrible...chicks don't belong in the bo...      sexist  \n",
       "28  The ideal marriage is one in which the husband...  non-sexist  \n",
       "29  Every man needs a woman when his life is a mes...      sexist  \n",
       "30  ABCDEFG means  A Boy Can Do Everything For a G...      sexist  \n",
       "31  Although there are exceptions, nagging and dom...      sexist  \n",
       "32  The left would anyone with a brain could tell ...  non-sexist  \n",
       "33  Oh, I have one too!!!  @MT8_9 @HisFeministMama...  non-sexist  \n",
       "34  @Anjie2006 I preferred Marilyn mornings.   Hiy...  non-sexist  \n",
       "35  @shacks2cents @JustLaurenB It's actually two s...  non-sexist  \n",
       "36  female wrestling is as exciting as watching gr...      sexist  \n",
       "37  RT Clairelouo: piersmorgan I am a housewife an...  non-sexist  \n",
       "38  \"@LaHurston1: a girl on the phone while drivin...      sexist  \n",
       "39  Sucks to have the smile wiped off your own fac...  non-sexist  \n",
       "40  #mkr I think Colin might not be a fan of the m...  non-sexist  \n",
       "41  @PeterWallaceAU @kimbakit its a very good poin...      sexist  \n",
       "42  A man should be able to openly show affection ...  non-sexist  \n",
       "43  @WorldOfStu @BadtotheBohn @bbarber67 @glennbec...  non-sexist  \n",
       "44  Women should be prepared to oppose men in orde...  non-sexist  \n",
       "45  The influx of women into the business world in...      sexist  \n",
       "46  Women are inferior to men in their cognitive a...      sexist  \n",
       "47  Women weren't created to do the things men can...      sexist  \n",
       "48  I'm not a huge fan of woman singers (I dare yo...  non-sexist  \n",
       "49  Women seek to gain power by getting control ov...      sexist  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fec44b-ebd7-4ec2-906f-b1b15e92d51e",
   "metadata": {},
   "source": [
    "## Classification w LLaMa models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85512806-4dc3-4c01-8610-40a03250ed42",
   "metadata": {},
   "source": [
    "#### Step 1, do participant definitions, LLaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "404dcba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35023cf4-9a2a-4530-a3a3-5a3000f58e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.37s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.52s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:21<00:00,  2.14s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.30s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# for each test set\n",
    "results_participantdef_GPT4o = {}\n",
    "\n",
    "for domain, test_set in test_set_data[\"sexism\"].items():\n",
    "    # we have a result dictionary of dictionaries per participant\n",
    "    result_dict = defaultdict()\n",
    "    for participant, participant_dict in def_dict.items():\n",
    "            part_dict = defaultdict()\n",
    "            for _, row in tqdm(test_set_data[\"sexism\"][domain].iterrows(),\n",
    "                               total=test_set_data[\"sexism\"][domain].shape[0]):\n",
    "                prompt = add_texts_to_prompts(participant_dict, \n",
    "                                          \"prompt_definition_participant\", \n",
    "                                          row[\"text\"])\n",
    "                try:\n",
    "                    responses = client.chat_completion(\n",
    "                        model=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                        # response_format=response_format,\n",
    "                        stream=False)\n",
    "                    \n",
    "#                     responses = client.chat.completions.create(model=GPT_4o,\n",
    "#                                                                messages=[{\"role\": \"user\", \n",
    "#                                                                       \"content\": prompt}],\n",
    "#                                                                         temperature=0,\n",
    "#                                                                          max_tokens=200,\n",
    "#                                                                          top_p=1,\n",
    "#                                                                          frequency_penalty=0,\n",
    "#                                                                          presence_penalty=0)                                                                    \n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    responses = client.chat_completion(\n",
    "                        model=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                        # response_format=response_format,\n",
    "                        stream=False)\n",
    "                part_dict[row[\"_id\"]] = responses.choices[0].message.content                                                          \n",
    "            results_participantdef_GPT4o[participant] = part_dict \n",
    "            result_dict['LlaMa3_70b'] = results_participantdef_GPT4o\n",
    "    test_set_data['sexism'][domain][\"results\"] = str(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e81c76c-aa59-475a-8877-31bd6f3090b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_500items_llama.txt\", \"w+\") as f:\n",
    "    f.write(str(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fae40885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {36: '1) sexist',\n",
       "             2009: '1) sexist',\n",
       "             596: '1) sexist',\n",
       "             1974: '1) sexist',\n",
       "             2317: '2) non-sexist',\n",
       "             3834: '1) sexist',\n",
       "             1046: '2) non-sexist',\n",
       "             3306: '1) sexist',\n",
       "             2791: 'non-sexist',\n",
       "             337: '1) sexist'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[\"LlaMa3_70b\"]['EXP_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c3fcb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {36: '1) sexist',\n",
       "             2009: '1) sexist',\n",
       "             596: '1) sexist',\n",
       "             1974: '1) sexist',\n",
       "             2317: '2) non-sexist',\n",
       "             3834: '1) sexist',\n",
       "             1046: '2) non-sexist',\n",
       "             3306: '1) sexist',\n",
       "             2791: 'non-sexist',\n",
       "             337: '1) sexist'})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[\"LlaMa3_70b\"]['EXP_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d7f0429-96db-4ffe-b8b7-e48f487f0f38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.80      0.50      0.62         8\n",
      "      sexist       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.50      0.50      0.45        10\n",
      "weighted avg       0.68      0.50      0.55        10\n",
      "\n",
      "\n",
      "EXP_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       1.00      0.25      0.40         8\n",
      "      sexist       0.25      1.00      0.40         2\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.62      0.62      0.40        10\n",
      "weighted avg       0.85      0.40      0.40        10\n",
      "\n",
      "\n",
      "EXP_6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.75      0.38      0.50         8\n",
      "      sexist       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.46      0.44      0.38        10\n",
      "weighted avg       0.63      0.40      0.45        10\n",
      "\n",
      "\n",
      "EXP_7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.25      0.36         8\n",
      "      sexist       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.40      0.38      0.29        10\n",
      "weighted avg       0.56      0.30      0.34        10\n",
      "\n",
      "\n",
      "EXP_11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       1.00      0.25      0.40         8\n",
      "      sexist       0.25      1.00      0.40         2\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.62      0.62      0.40        10\n",
      "weighted avg       0.85      0.40      0.40        10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# change the label extraction because it seems to be different for llama\n",
    "\n",
    "for participant in result_dict[\"LlaMa3_70b\"].keys():\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] if len(i.split(\")\")) > 1 else i\\\n",
    "              for i in result_dict[\"LlaMa3_70b\"][participant].values()]\n",
    "    labels = [i if i in (['sexist', 'non-sexist']) else 'non-sexist' for i in labels] # defaults to 'non-sexist'\n",
    "#     print(labels)\n",
    "    \n",
    "    truth = test_set_data[\"sexism\"][\"in_domain\"][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21ead023-a7f4-4ecb-9746-614f09f5ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sexism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>Disgusted by all the women around here.</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2009</td>\n",
       "      <td>What if we just killed all women?</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>596</td>\n",
       "      <td>I'm going to stab a woman tomorrow.</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1974</td>\n",
       "      <td>Isn't it typical of a woman to be that stupid?</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2317</td>\n",
       "      <td>There are very few women at my school.</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3834</td>\n",
       "      <td>You are nothing but a b1tch.</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1046</td>\n",
       "      <td>I keep two garden hoes out in my tool shed.</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>3306</td>\n",
       "      <td>Womn belong in a zoo.</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2791</td>\n",
       "      <td>It hurts to see all these people saying female...</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>337</td>\n",
       "      <td>Women are lesser beings.</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id                                               text      sexism\n",
       "5      36           Disgusted by all the women around here.       sexist\n",
       "277  2009                  What if we just killed all women?      sexist\n",
       "85    596               I'm going to stab a woman tomorrow.       sexist\n",
       "272  1974     Isn't it typical of a woman to be that stupid?      sexist\n",
       "318  2317            There are very few women at my school.   non-sexist\n",
       "498  3834                      You are nothing but a b1tch.       sexist\n",
       "148  1046       I keep two garden hoes out in my tool shed.   non-sexist\n",
       "425  3306                             Womn belong in a zoo.       sexist\n",
       "384  2791  It hurts to see all these people saying female...  non-sexist\n",
       "48    337                          Women are lesser beings.       sexist"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data[\"sexism\"][domain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac577e01-0326-4af8-818d-2ed063a88672",
   "metadata": {},
   "source": [
    "### Step 2, do GPT 1 definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c016d20f-53fa-4006-bcfa-4d345d30dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each test set\n",
    "for domain, test_set in test_set_data[\"sexism\"].items():\n",
    "    # we have a result dictionary of dictionaries per participant\n",
    "    result_dict = defaultdict()\n",
    "    for participant, participant_dict in def_dict.items():\n",
    "            part_dict = defaultdict()\n",
    "            for _, row in test_set_data[\"sexism\"][domain].iterrows():\n",
    "                prompt = add_texts_to_prompts(participant_dict, \n",
    "                                          \"prompt_definition_ChatGPT_1\", \n",
    "                                          row[\"text\"])\n",
    "                try:\n",
    "                    responses = client.chat_completion(\n",
    "                        model=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                        # response_format=response_format,\n",
    "                        stream=False)                                                                    \n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    responses = client.chat_completion(\n",
    "                        model=\"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                        # response_format=response_format,\n",
    "                        stream=False) \n",
    "                part_dict[row[\"_id\"]] = responses.choices[0].message.content                                                          \n",
    "            results_participantdef_GPT4o[participant] = part_dict \n",
    "            result_dict[domain] = results_participantdef_GPT4o\n",
    "    test_set_data['sexism'][domain][\"results_llamadef1\"] = str(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6929eae4-2468-4069-b3e8-8c619f0415cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not collections.defaultdict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_500items_llamadef1.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(result_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not collections.defaultdict"
     ]
    }
   ],
   "source": [
    "with open(\"F1_500items_llamadef1.txt\", \"w+\") as f:\n",
    "    f.write(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f73c15-86a9-42e6-88e5-fb2d63598bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for participant in result_dict[\"GPT4o\"].keys():\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"GPT4o\"][participant].values()]\n",
    "#     print(labels)\n",
    "    truth = test_set_data[\"sexism\"][\"in_domain\"][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc4784-8c28-4147-9755-19e808efab44",
   "metadata": {},
   "source": [
    "### Step 3 do GPT 10 definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d285b-14a3-4fb4-8dd0-a4993f4d1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each test set\n",
    "for domain, test_set in test_set_data[\"sexism\"].items():\n",
    "    # we have a result dictionary of dictionaries per participant\n",
    "    result_dict = defaultdict()\n",
    "    for participant, participant_dict in def_dict.items():\n",
    "            part_dict = defaultdict()\n",
    "            for _, row in test_set_data[\"sexism\"][domain].iterrows():\n",
    "                prompt = add_texts_to_prompts(participant_dict, \n",
    "                                          \"prompt_definition_chosen_10\", \n",
    "                                          row[\"text\"])\n",
    "                try:\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0)                                                                    \n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    responses = client.chat.completions.create(model=GPT_4o,\n",
    "                                                               messages=[{\"role\": \"user\", \n",
    "                                                                      \"content\": prompt}],\n",
    "                                                                        temperature=0,\n",
    "                                                                         max_tokens=200,\n",
    "                                                                         top_p=1,\n",
    "                                                                         frequency_penalty=0,\n",
    "                                                                         presence_penalty=0) \n",
    "                part_dict[row[\"_id\"]] = responses.choices[0].message.content                                                          \n",
    "            results_participantdef_GPT4o[participant] = part_dict \n",
    "            result_dict[domain] = results_participantdef_GPT4o\n",
    "    test_set_data['sexism'][domain][\"results_GPTdef10\"] = str(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f6a7e-cda2-4015-b37c-7549785f0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F1_500items_GPTdef10.txt\", \"w+\") as f:\n",
    "    f.write(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd8ff8-4a25-4725-8e16-b8b35f9d1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for participant in result_dict[\"GPT4o\"].keys():\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"GPT4o\"][participant].values()]\n",
    "#     print(labels)\n",
    "    truth = test_set_data[\"sexism\"][\"in_domain\"][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72056d44-0a6a-4d66-8720-b56d6518bcf1",
   "metadata": {},
   "source": [
    "### Step 4, do F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7906cf2-53e5-4672-aed6-7d74fd387ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "451265b7-13de-43b9-8899-c522e9f077c0",
   "metadata": {},
   "source": [
    "### Step 5, visualize F1 scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84e778-e49f-4bf7-9c3e-8669a19e8c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
