{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = pd.read_pickle(\"Loop3_results_dict_of_dfs.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make metrics dataframe for GPT definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n",
      "skip\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "definitions = [\"results_GPTdef10\", \"results_GPTdef1\"]\n",
    "experts = [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\",\"EXP_10\",\"EXP_11\"]\n",
    "\n",
    "for dataset in results_all[\"sexism\"].keys():\n",
    "    for definition in definitions:\n",
    "        for expert in experts: \n",
    "            for i in results_all[\"sexism\"][dataset][definition][:2]:\n",
    "                result_dict = eval(i)\n",
    "#                 print(result_dict)\n",
    "                try:\n",
    "                    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[dataset][expert].values()]\n",
    "                    labels = [\"non-sexist\" if i == \"can’t say\" or i == \"can't say\" else i for i in labels] \n",
    "                    truth = results_all[\"sexism\"][dataset][\"sexism\"].tolist()\n",
    "                    scores = classification_report(truth, labels, output_dict=True,zero_division=0)\n",
    "\n",
    "                    temp_dict = pd.DataFrame()\n",
    "\n",
    "                    temp_dict[\"definition\"] = [definition]\n",
    "                    temp_dict[\"expert\"] = expert\n",
    "                    temp_dict[\"dataset\"] = dataset\n",
    "                    temp_dict[\"scores\"] = [scores]\n",
    "\n",
    "                    metrics_df = pd.concat([metrics_df, temp_dict])\n",
    "                except:\n",
    "                    print(\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the participant definitions to this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in results_all[\"sexism\"].keys():\n",
    "    for definition in [\"results\"]:\n",
    "        for expert in experts: \n",
    "            for i in results_all[\"sexism\"][dataset][definition][:2]:\n",
    "                result_dict = eval(i)\n",
    "#                 print(result_dict)\n",
    "                try:\n",
    "                    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"GPT4o\"][expert].values()]\n",
    "                    labels = [\"non-sexist\" if i == \"can’t say\" or i == \"can't say\" else i for i in labels] \n",
    "                    truth = results_all[\"sexism\"][dataset][\"sexism\"].tolist()\n",
    "                    scores = classification_report(truth, labels, output_dict=True)\n",
    "\n",
    "                    temp_dict = pd.DataFrame()\n",
    "\n",
    "                    temp_dict[\"definition\"] = [definition]\n",
    "                    temp_dict[\"expert\"] = expert\n",
    "                    temp_dict[\"dataset\"] = dataset\n",
    "                    temp_dict[\"scores\"] = [scores]\n",
    "\n",
    "                    metrics_df = pd.concat([metrics_df, temp_dict])\n",
    "                except:\n",
    "                    print(\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df[\"definition\"] = metrics_df[\"definition\"].replace(\"results_GPTdef10\", \"hybrid\")\n",
    "metrics_df[\"definition\"] = metrics_df[\"definition\"].replace(\"results_GPTdef1\", \"GPT\")\n",
    "metrics_df[\"definition\"] = metrics_df[\"definition\"].replace(\"results\", \"participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'non-sexist': {'precision': 0.9333333333333333, 'recall': 0.7608695652173914, 'f1-score': 0.8383233532934132, 'support': 276}, 'sexist': {'precision': 0.76, 'recall': 0.9330357142857143, 'f1-score': 0.8376753507014029, 'support': 224}, 'accuracy': 0.838, 'macro avg': {'precision': 0.8466666666666667, 'recall': 0.8469526397515528, 'f1-score': 0.837999351997408, 'support': 500}, 'weighted avg': {'precision': 0.8556800000000001, 'recall': 0.838, 'f1-score': 0.8380330481321926, 'support': 500}}\n"
     ]
    }
   ],
   "source": [
    "for i in metrics_df[\"scores\"][:1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add individual metrics to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definition</th>\n",
       "      <th>expert</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scores</th>\n",
       "      <th>F1</th>\n",
       "      <th>sexist_F1</th>\n",
       "      <th>non_sexist_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0.831957</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0.831957</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_3</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.806584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_9</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.267857142857142...</td>\n",
       "      <td>0.483775</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.336134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     definition  expert    dataset  \\\n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_3  in_domain   \n",
       "..          ...     ...        ...   \n",
       "0   participant   EXP_9  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "\n",
       "                                               scores        F1  sexist_F1  \\\n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.837999   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.837999   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...  0.831957   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...  0.831957   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.811852   0.817121   \n",
       "..                                                ...       ...        ...   \n",
       "0   {'non-sexist': {'precision': 0.267857142857142...  0.483775   0.631415   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...  0.476382   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...  0.476382   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...  0.484414   0.623622   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...  0.484414   0.623622   \n",
       "\n",
       "    non_sexist_F1  \n",
       "0        0.838323  \n",
       "0        0.838323  \n",
       "0        0.834646  \n",
       "0        0.834646  \n",
       "0        0.806584  \n",
       "..            ...  \n",
       "0        0.336134  \n",
       "0        0.291022  \n",
       "0        0.291022  \n",
       "0        0.345205  \n",
       "0        0.345205  \n",
       "\n",
       "[328 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1s = []\n",
    "in_sex = []\n",
    "in_non = []\n",
    "\n",
    "for index, row in metrics_df.iterrows():\n",
    "    F1 = dict(row[\"scores\"])[\"macro avg\"][\"f1-score\"]\n",
    "    class_sexism_f1 = dict(row[\"scores\"])[\"sexist\"][\"f1-score\"]\n",
    "    non_sex = dict(row[\"scores\"])[\"non-sexist\"][\"f1-score\"]\n",
    "    F1s.append(F1)\n",
    "    in_sex.append(class_sexism_f1)\n",
    "    in_non.append(non_sex)\n",
    "    \n",
    "#     print(F1)\n",
    "#     print(in_sex)\n",
    "\n",
    "metrics_df[\"F1\"] = F1s\n",
    "metrics_df[\"sexist_F1\"] = in_sex\n",
    "metrics_df[\"non_sexist_F1\"] = in_non\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data of duplicates and participants who didn't do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = metrics_df[metrics_df[[\"definition\", \"expert\", \"dataset\", \"F1\", \"sexist_F1\", \"non_sexist_F1\"]].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definition</th>\n",
       "      <th>expert</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scores</th>\n",
       "      <th>F1</th>\n",
       "      <th>sexist_F1</th>\n",
       "      <th>non_sexist_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0.831957</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_3</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.806584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_4</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.938095238095238...</td>\n",
       "      <td>0.815856</td>\n",
       "      <td>0.821012</td>\n",
       "      <td>0.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_5</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.921739130434782...</td>\n",
       "      <td>0.835976</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.837945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_7</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.266375545851528...</td>\n",
       "      <td>0.480421</td>\n",
       "      <td>0.623824</td>\n",
       "      <td>0.337017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_8</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.269911504424778...</td>\n",
       "      <td>0.485049</td>\n",
       "      <td>0.630265</td>\n",
       "      <td>0.339833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_9</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.267857142857142...</td>\n",
       "      <td>0.483775</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.336134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     definition  expert    dataset  \\\n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_3  in_domain   \n",
       "0        hybrid   EXP_4  in_domain   \n",
       "0        hybrid   EXP_5  in_domain   \n",
       "..          ...     ...        ...   \n",
       "0   participant   EXP_7  hatecheck   \n",
       "0   participant   EXP_8  hatecheck   \n",
       "0   participant   EXP_9  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "\n",
       "                                               scores        F1  sexist_F1  \\\n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.837999   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...  0.831957   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.811852   0.817121   \n",
       "0   {'non-sexist': {'precision': 0.938095238095238...  0.815856   0.821012   \n",
       "0   {'non-sexist': {'precision': 0.921739130434782...  0.835976   0.834008   \n",
       "..                                                ...       ...        ...   \n",
       "0   {'non-sexist': {'precision': 0.266375545851528...  0.480421   0.623824   \n",
       "0   {'non-sexist': {'precision': 0.269911504424778...  0.485049   0.630265   \n",
       "0   {'non-sexist': {'precision': 0.267857142857142...  0.483775   0.631415   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...  0.476382   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...  0.484414   0.623622   \n",
       "\n",
       "    non_sexist_F1  \n",
       "0        0.838323  \n",
       "0        0.834646  \n",
       "0        0.806584  \n",
       "0        0.810700  \n",
       "0        0.837945  \n",
       "..            ...  \n",
       "0        0.337017  \n",
       "0        0.339833  \n",
       "0        0.336134  \n",
       "0        0.291022  \n",
       "0        0.345205  \n",
       "\n",
       "[164 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(12):\n",
    "#     filtered_data = clean_data[clean_data[\"expert\"] == f\"EXP_{i}\"]\n",
    "#     print(filtered_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[\"dataset\"] = clean_data[\"dataset\"].replace(\"in_domain\", \"CallMeSexist\")\n",
    "clean_data[\"dataset\"] = clean_data[\"dataset\"].replace(\"out_of_domain_3\", \"EDOS\")\n",
    "clean_data[\"dataset\"] = clean_data[\"dataset\"].replace(\"out_of_domain_2\", \"RedditGuest\")\n",
    "clean_data[\"dataset\"] = clean_data[\"dataset\"].replace(\"out_of_domain\", \"EXIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data[clean_data.expert != \"EXP_8\"]\n",
    "clean_data = clean_data[clean_data.expert != \"EXP_7\"]\n",
    "clean_data\n",
    "\n",
    "clean_data.to_pickle('cleaned_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definition</th>\n",
       "      <th>expert</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scores</th>\n",
       "      <th>F1</th>\n",
       "      <th>sexist_F1</th>\n",
       "      <th>non_sexist_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>CallMeSexist</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>CallMeSexist</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0.831957</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_3</td>\n",
       "      <td>CallMeSexist</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.806584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_4</td>\n",
       "      <td>CallMeSexist</td>\n",
       "      <td>{'non-sexist': {'precision': 0.938095238095238...</td>\n",
       "      <td>0.815856</td>\n",
       "      <td>0.821012</td>\n",
       "      <td>0.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_5</td>\n",
       "      <td>CallMeSexist</td>\n",
       "      <td>{'non-sexist': {'precision': 0.921739130434782...</td>\n",
       "      <td>0.835976</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.837945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_5</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.265384615384615...</td>\n",
       "      <td>0.465523</td>\n",
       "      <td>0.579901</td>\n",
       "      <td>0.351145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_6</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.275229357798165...</td>\n",
       "      <td>0.492974</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.341880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_9</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.267857142857142...</td>\n",
       "      <td>0.483775</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.336134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     definition  expert       dataset  \\\n",
       "0        hybrid   EXP_1  CallMeSexist   \n",
       "0        hybrid   EXP_2  CallMeSexist   \n",
       "0        hybrid   EXP_3  CallMeSexist   \n",
       "0        hybrid   EXP_4  CallMeSexist   \n",
       "0        hybrid   EXP_5  CallMeSexist   \n",
       "..          ...     ...           ...   \n",
       "0   participant   EXP_5     hatecheck   \n",
       "0   participant   EXP_6     hatecheck   \n",
       "0   participant   EXP_9     hatecheck   \n",
       "0   participant  EXP_10     hatecheck   \n",
       "0   participant  EXP_11     hatecheck   \n",
       "\n",
       "                                               scores        F1  sexist_F1  \\\n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.837999   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...  0.831957   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...  0.811852   0.817121   \n",
       "0   {'non-sexist': {'precision': 0.938095238095238...  0.815856   0.821012   \n",
       "0   {'non-sexist': {'precision': 0.921739130434782...  0.835976   0.834008   \n",
       "..                                                ...       ...        ...   \n",
       "0   {'non-sexist': {'precision': 0.265384615384615...  0.465523   0.579901   \n",
       "0   {'non-sexist': {'precision': 0.275229357798165...  0.492974   0.644068   \n",
       "0   {'non-sexist': {'precision': 0.267857142857142...  0.483775   0.631415   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...  0.476382   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...  0.484414   0.623622   \n",
       "\n",
       "    non_sexist_F1  \n",
       "0        0.838323  \n",
       "0        0.834646  \n",
       "0        0.806584  \n",
       "0        0.810700  \n",
       "0        0.837945  \n",
       "..            ...  \n",
       "0        0.351145  \n",
       "0        0.341880  \n",
       "0        0.336134  \n",
       "0        0.291022  \n",
       "0        0.345205  \n",
       "\n",
       "[134 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "definition\n",
       "GPT            0.113551\n",
       "hybrid         0.120875\n",
       "participant    0.154190\n",
       "Name: F1, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.groupby(\"definition\")[\"F1\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "definition\n",
       "GPT            0.837355\n",
       "hybrid         0.834876\n",
       "participant    0.557013\n",
       "Name: non_sexist_F1, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.groupby([\"definition\"])[\"non_sexist_F1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset       definition \n",
       "CallMeSexist  GPT            0.813739\n",
       "              hybrid         0.812609\n",
       "              participant    0.823685\n",
       "EDOS          GPT            0.807345\n",
       "              hybrid         0.811304\n",
       "              participant    0.564190\n",
       "EXIST         GPT            0.809151\n",
       "              hybrid         0.811036\n",
       "              participant    0.475008\n",
       "RedditGuest   GPT            0.894011\n",
       "              hybrid         0.888337\n",
       "              participant    0.583967\n",
       "hatecheck     GPT            0.859397\n",
       "              hybrid         0.851093\n",
       "              participant    0.338215\n",
       "Name: non_sexist_F1, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.groupby([\"dataset\", \"definition\"])[\"non_sexist_F1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset       definition \n",
       "CallMeSexist  GPT            0.819466\n",
       "              hybrid         0.819820\n",
       "              participant    0.825639\n",
       "EDOS          GPT            0.622110\n",
       "              hybrid         0.627971\n",
       "              participant    0.330570\n",
       "EXIST         GPT            0.740047\n",
       "              hybrid         0.749110\n",
       "              participant    0.509250\n",
       "RedditGuest   GPT            0.558176\n",
       "              hybrid         0.544955\n",
       "              participant    0.203922\n",
       "hatecheck     GPT            0.954368\n",
       "              hybrid         0.951913\n",
       "              participant    0.635904\n",
       "Name: sexist_F1, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.groupby([\"dataset\", \"definition\"])[\"sexist_F1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-e6aef083c138>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  clean_data.groupby([\"expert\", \"definition\"])[\"F1\", \"sexist_F1\", \"non_sexist_F1\"].mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>sexist_F1</th>\n",
       "      <th>non_sexist_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert</th>\n",
       "      <th>definition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_1</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.744246</td>\n",
       "      <td>0.744452</td>\n",
       "      <td>0.841634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.741641</td>\n",
       "      <td>0.741673</td>\n",
       "      <td>0.837508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.528762</td>\n",
       "      <td>0.508039</td>\n",
       "      <td>0.549485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_10</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.796137</td>\n",
       "      <td>0.742001</td>\n",
       "      <td>0.850272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.784107</td>\n",
       "      <td>0.736482</td>\n",
       "      <td>0.831731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.505567</td>\n",
       "      <td>0.506695</td>\n",
       "      <td>0.504438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_11</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.740651</td>\n",
       "      <td>0.740151</td>\n",
       "      <td>0.839322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.723369</td>\n",
       "      <td>0.732582</td>\n",
       "      <td>0.808814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.533880</td>\n",
       "      <td>0.496867</td>\n",
       "      <td>0.570893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_2</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.745096</td>\n",
       "      <td>0.743421</td>\n",
       "      <td>0.845247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.785828</td>\n",
       "      <td>0.731277</td>\n",
       "      <td>0.840378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.531685</td>\n",
       "      <td>0.504144</td>\n",
       "      <td>0.559226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_3</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.784345</td>\n",
       "      <td>0.736838</td>\n",
       "      <td>0.831852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.734729</td>\n",
       "      <td>0.736772</td>\n",
       "      <td>0.827774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.532776</td>\n",
       "      <td>0.502817</td>\n",
       "      <td>0.562735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_4</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.784440</td>\n",
       "      <td>0.734373</td>\n",
       "      <td>0.834506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.788122</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.835003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.531668</td>\n",
       "      <td>0.506638</td>\n",
       "      <td>0.556697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_5</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.737392</td>\n",
       "      <td>0.738024</td>\n",
       "      <td>0.830754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.756336</td>\n",
       "      <td>0.749429</td>\n",
       "      <td>0.859477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.539335</td>\n",
       "      <td>0.480943</td>\n",
       "      <td>0.597728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_6</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.777784</td>\n",
       "      <td>0.731774</td>\n",
       "      <td>0.823794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.739151</td>\n",
       "      <td>0.739088</td>\n",
       "      <td>0.835664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.527122</td>\n",
       "      <td>0.503635</td>\n",
       "      <td>0.550610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">EXP_9</th>\n",
       "      <th>GPT</th>\n",
       "      <td>0.787788</td>\n",
       "      <td>0.737329</td>\n",
       "      <td>0.838246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>0.788885</td>\n",
       "      <td>0.740239</td>\n",
       "      <td>0.837532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>0.530519</td>\n",
       "      <td>0.499734</td>\n",
       "      <td>0.561304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1  sexist_F1  non_sexist_F1\n",
       "expert definition                                     \n",
       "EXP_1  GPT          0.744246   0.744452       0.841634\n",
       "       hybrid       0.741641   0.741673       0.837508\n",
       "       participant  0.528762   0.508039       0.549485\n",
       "EXP_10 GPT          0.796137   0.742001       0.850272\n",
       "       hybrid       0.784107   0.736482       0.831731\n",
       "       participant  0.505567   0.506695       0.504438\n",
       "EXP_11 GPT          0.740651   0.740151       0.839322\n",
       "       hybrid       0.723369   0.732582       0.808814\n",
       "       participant  0.533880   0.496867       0.570893\n",
       "EXP_2  GPT          0.745096   0.743421       0.845247\n",
       "       hybrid       0.785828   0.731277       0.840378\n",
       "       participant  0.531685   0.504144       0.559226\n",
       "EXP_3  GPT          0.784345   0.736838       0.831852\n",
       "       hybrid       0.734729   0.736772       0.827774\n",
       "       participant  0.532776   0.502817       0.562735\n",
       "EXP_4  GPT          0.784440   0.734373       0.834506\n",
       "       hybrid       0.788122   0.741242       0.835003\n",
       "       participant  0.531668   0.506638       0.556697\n",
       "EXP_5  GPT          0.737392   0.738024       0.830754\n",
       "       hybrid       0.756336   0.749429       0.859477\n",
       "       participant  0.539335   0.480943       0.597728\n",
       "EXP_6  GPT          0.777784   0.731774       0.823794\n",
       "       hybrid       0.739151   0.739088       0.835664\n",
       "       participant  0.527122   0.503635       0.550610\n",
       "EXP_9  GPT          0.787788   0.737329       0.838246\n",
       "       hybrid       0.788885   0.740239       0.837532\n",
       "       participant  0.530519   0.499734       0.561304"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.groupby([\"expert\", \"definition\"])[\"F1\", \"sexist_F1\", \"non_sexist_F1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  --------  --------  --------\n",
      "('EXP_1', 'GPT')           0.744246  0.744452  0.841634\n",
      "('EXP_1', 'hybrid')        0.741641  0.741673  0.837508\n",
      "('EXP_1', 'participant')   0.528762  0.508039  0.549485\n",
      "('EXP_10', 'GPT')          0.796137  0.742001  0.850272\n",
      "('EXP_10', 'hybrid')       0.784107  0.736482  0.831731\n",
      "('EXP_10', 'participant')  0.505567  0.506695  0.504438\n",
      "('EXP_11', 'GPT')          0.740651  0.740151  0.839322\n",
      "('EXP_11', 'hybrid')       0.723369  0.732582  0.808814\n",
      "('EXP_11', 'participant')  0.53388   0.496867  0.570893\n",
      "('EXP_2', 'GPT')           0.745096  0.743421  0.845247\n",
      "('EXP_2', 'hybrid')        0.785828  0.731277  0.840378\n",
      "('EXP_2', 'participant')   0.531685  0.504144  0.559226\n",
      "('EXP_3', 'GPT')           0.784345  0.736838  0.831852\n",
      "('EXP_3', 'hybrid')        0.734729  0.736772  0.827774\n",
      "('EXP_3', 'participant')   0.532776  0.502817  0.562735\n",
      "('EXP_4', 'GPT')           0.78444   0.734373  0.834506\n",
      "('EXP_4', 'hybrid')        0.788122  0.741242  0.835003\n",
      "('EXP_4', 'participant')   0.531668  0.506638  0.556697\n",
      "('EXP_5', 'GPT')           0.737392  0.738024  0.830754\n",
      "('EXP_5', 'hybrid')        0.756336  0.749429  0.859477\n",
      "('EXP_5', 'participant')   0.539335  0.480943  0.597728\n",
      "('EXP_6', 'GPT')           0.777784  0.731774  0.823794\n",
      "('EXP_6', 'hybrid')        0.739151  0.739088  0.835664\n",
      "('EXP_6', 'participant')   0.527122  0.503635  0.55061\n",
      "('EXP_9', 'GPT')           0.787788  0.737329  0.838246\n",
      "('EXP_9', 'hybrid')        0.788885  0.740239  0.837532\n",
      "('EXP_9', 'participant')   0.530519  0.499734  0.561304\n",
      "-------------------------  --------  --------  --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-231fdc0680bd>:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  print(tabulate(clean_data.groupby([\"expert\", \"definition\"])[\"F1\", \"sexist_F1\", \"non_sexist_F1\"].mean()))\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(tabulate(clean_data.groupby([\"expert\", \"definition\"])[\"F1\", \"sexist_F1\", \"non_sexist_F1\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-d67305dbb410>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-d67305dbb410>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dataset       definition\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dataset       definition \n",
    "CallMeSexist  GPT            0.814498\n",
    "              hybrid         0.822511\n",
    "              participant    0.826991\n",
    "EDOS          GPT            0.711774\n",
    "              hybrid         0.726304\n",
    "              participant    0.450252\n",
    "EXIST         GPT            0.778799\n",
    "              hybrid         0.776701\n",
    "              participant    0.494881\n",
    "RedditGuest   GPT            0.619981\n",
    "              hybrid         0.581450\n",
    "              participant    0.397389\n",
    "hatecheck     GPT            0.903492\n",
    "              hybrid         0.903530\n",
    "              participant    0.488963\n",
    "Name: F1, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expert  definition \n",
       "EXP_1   GPT            0.744246\n",
       "        hybrid         0.741641\n",
       "        participant    0.528762\n",
       "EXP_2   GPT            0.745096\n",
       "        hybrid         0.785828\n",
       "        participant    0.531685\n",
       "EXP_3   GPT            0.784345\n",
       "        hybrid         0.734729\n",
       "        participant    0.532776\n",
       "EXP_4   GPT            0.784440\n",
       "        hybrid         0.788122\n",
       "        participant    0.531668\n",
       "EXP_5   GPT            0.737392\n",
       "        hybrid         0.756336\n",
       "        participant    0.539335\n",
       "EXP_6   GPT            0.777784\n",
       "        hybrid         0.739151\n",
       "        participant    0.527122\n",
       "EXP_9   GPT            0.787788\n",
       "        hybrid         0.788885\n",
       "        participant    0.530519\n",
       "EXP_10  GPT            0.796137\n",
       "        hybrid         0.784107\n",
       "        participant    0.505567\n",
       "EXP_11  GPT            0.740651\n",
       "        hybrid         0.723369\n",
       "        participant    0.533880\n",
       "Name: F1, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'expert' column to a categorical type with the desired order\n",
    "clean_data[\"expert\"] = pd.Categorical(\n",
    "    clean_data[\"expert\"],\n",
    "    categories=sorted(clean_data[\"expert\"].unique(), key=lambda x: int(x.split('_')[1])),\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "clean_data.groupby([\"expert\", \"definition\"])[\"F1\"].mean().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definition</th>\n",
       "      <th>expert</th>\n",
       "      <th>dataset</th>\n",
       "      <th>scores</th>\n",
       "      <th>F1</th>\n",
       "      <th>sexist_F1</th>\n",
       "      <th>non_sexist_F1</th>\n",
       "      <th>(0, F1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_1</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837675</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_2</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.913793103448275...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>EXP_3</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>{'non-sexist': {'precision': 0.933333333333333...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_9</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.267857142857142...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_10</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.247368421052631...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661743</td>\n",
       "      <td>0.291022</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>EXP_11</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>{'non-sexist': {'precision': 0.271551724137931...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623622</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.484414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     definition  expert    dataset  \\\n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_1  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_2  in_domain   \n",
       "0        hybrid   EXP_3  in_domain   \n",
       "..          ...     ...        ...   \n",
       "0   participant   EXP_9  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_10  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "0   participant  EXP_11  hatecheck   \n",
       "\n",
       "                                               scores  F1  sexist_F1  \\\n",
       "0   {'non-sexist': {'precision': 0.933333333333333...   0   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...   0   0.837675   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...   0   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.913793103448275...   0   0.829268   \n",
       "0   {'non-sexist': {'precision': 0.933333333333333...   0   0.817121   \n",
       "..                                                ...  ..        ...   \n",
       "0   {'non-sexist': {'precision': 0.267857142857142...   0   0.631415   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...   0   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.247368421052631...   0   0.661743   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...   0   0.623622   \n",
       "0   {'non-sexist': {'precision': 0.271551724137931...   0   0.623622   \n",
       "\n",
       "    non_sexist_F1   (0, F1)  \n",
       "0        0.838323  0.484414  \n",
       "0        0.838323  0.484414  \n",
       "0        0.834646  0.484414  \n",
       "0        0.834646  0.484414  \n",
       "0        0.806584  0.484414  \n",
       "..            ...       ...  \n",
       "0        0.336134  0.484414  \n",
       "0        0.291022  0.484414  \n",
       "0        0.291022  0.484414  \n",
       "0        0.345205  0.484414  \n",
       "0        0.345205  0.484414  \n",
       "\n",
       "[328 rows x 8 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df[\"F1\"] = 0\n",
    "\n",
    "for index, row in metrics_df.iterrows():\n",
    "    metrics_df[index, \"F1\"] = dict(row[\"scores\"])[\"macro avg\"][\"f1-score\"]\n",
    "# #     metrics_df.loc[index, \"f1\"] = row[\"scores\"][\"macro avg\"][\"f1-score\"]\n",
    "#     print(row)\n",
    "    \n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3', #'out_of_domain_4', \n",
    "             'hatecheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_of_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.76      0.89      0.82       262\n",
      "      sexist       0.85      0.70      0.76       238\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.81      0.79      0.79       500\n",
      "weighted avg       0.80      0.80      0.79       500\n",
      "\n",
      "\n",
      "\n",
      "out_of_domain_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.98      0.81      0.88       435\n",
      "      sexist       0.40      0.85      0.54        65\n",
      "   sexist\n",
      "\n",
      "2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.46      0.55      0.48       500\n",
      "weighted avg       0.90      0.81      0.84       500\n",
      "\n",
      "\n",
      "\n",
      "out_of_domain_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.68      0.80       384\n",
      "      sexist       0.46      0.91      0.61       116\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.71      0.79      0.70       500\n",
      "weighted avg       0.84      0.73      0.75       500\n",
      "\n",
      "\n",
      "\n",
      "hatecheck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.95      0.74      0.83       133\n",
      "      sexist       0.91      0.99      0.95       367\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.93      0.86      0.89       500\n",
      "weighted avg       0.92      0.92      0.92       500\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# for i in results_all[\"sexism\"]['hatecheck'][\"results_GPTdef10\"]:\n",
    "#     result_dict = eval(i)\n",
    "#     print(result_dict)\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    for i in results_all[\"sexism\"][dataset][\"results_GPTdef10\"][:1]:\n",
    "        result_dict = eval(i)\n",
    "        labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[dataset][\"EXP_3\"].values()]\n",
    "        labels = [\"non-sexist\" if i == \"can’t say\" or i == \"can't say\" else i for i in labels] \n",
    "        #         print(labels)\n",
    "        truth = results_all[\"sexism\"][dataset][\"sexism\"].tolist()\n",
    "        print(classification_report(truth, labels))\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.89      0.77      0.83       133\n",
      "      sexist       0.92      0.96      0.94       367\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.90      0.87      0.89       500\n",
      "weighted avg       0.91      0.91      0.91       500\n",
      "\n",
      "\n",
      "EXP_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.86      0.81      0.83       133\n",
      "      sexist       0.93      0.95      0.94       367\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.90      0.88      0.89       500\n",
      "weighted avg       0.91      0.91      0.91       500\n",
      "\n",
      "\n",
      "EXP_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.95      0.74      0.83       133\n",
      "      sexist       0.91      0.99      0.95       367\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.93      0.86      0.89       500\n",
      "weighted avg       0.92      0.92      0.92       500\n",
      "\n",
      "\n",
      "EXP_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.95      0.80      0.87       133\n",
      "      sexist       0.93      0.98      0.96       367\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.94      0.89      0.91       500\n",
      "weighted avg       0.94      0.94      0.93       500\n",
      "\n",
      "\n",
      "EXP_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.86      0.92       133\n",
      "      sexist       0.95      0.99      0.97       367\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.93      0.94       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "\n",
      "EXP_6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.76      0.85       133\n",
      "      sexist       0.92      0.99      0.95       367\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.94      0.87      0.90       500\n",
      "weighted avg       0.93      0.93      0.93       500\n",
      "\n",
      "\n",
      "EXP_7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.84      0.90       133\n",
      "      sexist       0.95      0.99      0.97       367\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.96      0.92      0.93       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n",
      "\n",
      "EXP_8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.83      0.89       133\n",
      "      sexist       0.94      0.99      0.96       367\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.95      0.91      0.93       500\n",
      "weighted avg       0.95      0.95      0.94       500\n",
      "\n",
      "\n",
      "EXP_9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.91      0.80      0.86       133\n",
      "      sexist       0.93      0.97      0.95       367\n",
      "\n",
      "    accuracy                           0.93       500\n",
      "   macro avg       0.92      0.89      0.90       500\n",
      "weighted avg       0.93      0.93      0.93       500\n",
      "\n",
      "\n",
      "EXP_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.80      0.88       133\n",
      "      sexist       0.93      0.99      0.96       367\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.95      0.90      0.92       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n",
      "\n",
      "EXP_11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.95      0.69      0.80       133\n",
      "      sexist       0.90      0.99      0.94       367\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.92      0.84      0.87       500\n",
      "weighted avg       0.91      0.91      0.90       500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "for i in results_all[\"sexism\"]['hatecheck'][\"results_GPTdef10\"]:\n",
    "    result_dict = eval(i)\n",
    "#     print(result_dict)\n",
    "for participant in [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\", \"EXP_10\", \"EXP_11\"]:\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"hatecheck\"][participant].values()]\n",
    "    labels = [\"non-sexist\" if i == \"can’t say\" else i for i in labels] \n",
    "    #         print(labels)\n",
    "    truth = results_all[\"sexism\"]['hatecheck'][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.71      0.82       384\n",
      "      sexist       0.49      0.91      0.63       116\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.72      0.81      0.73       500\n",
      "weighted avg       0.85      0.76      0.78       500\n",
      "\n",
      "\n",
      "EXP_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.95      0.76      0.84       384\n",
      "      sexist       0.52      0.87      0.65       116\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.73      0.81      0.75       500\n",
      "weighted avg       0.85      0.78      0.80       500\n",
      "\n",
      "\n",
      "EXP_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.68      0.80       384\n",
      "      sexist       0.46      0.91      0.61       116\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.71      0.79      0.70       500\n",
      "weighted avg       0.84      0.73      0.75       500\n",
      "\n",
      "\n",
      "EXP_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.68      0.80       384\n",
      "      sexist       0.47      0.94      0.63       116\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.72      0.81      0.72       500\n",
      "weighted avg       0.86      0.74      0.76       500\n",
      "\n",
      "\n",
      "EXP_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.74      0.84       384\n",
      "      sexist       0.51      0.91      0.66       116\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.74      0.83      0.75       500\n",
      "weighted avg       0.86      0.78      0.80       500\n",
      "\n",
      "\n",
      "EXP_6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.70      0.81       384\n",
      "      sexist       0.48      0.92      0.63       116\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.72      0.81      0.72       500\n",
      "weighted avg       0.85      0.75      0.77       500\n",
      "\n",
      "\n",
      "EXP_7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.72      0.82       384\n",
      "      sexist       0.49      0.91      0.64       116\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.73      0.81      0.73       500\n",
      "weighted avg       0.85      0.76      0.78       500\n",
      "\n",
      "\n",
      "EXP_8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.72      0.82       384\n",
      "      sexist       0.50      0.91      0.64       116\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.73      0.81      0.73       500\n",
      "weighted avg       0.85      0.76      0.78       500\n",
      "\n",
      "\n",
      "EXP_9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.71      0.82       384\n",
      "      sexist       0.49      0.90      0.63       116\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.72      0.81      0.72       500\n",
      "weighted avg       0.85      0.76      0.77       500\n",
      "\n",
      "\n",
      "EXP_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.66      0.78       384\n",
      "      sexist       0.45      0.91      0.60       116\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.70      0.78      0.69       500\n",
      "weighted avg       0.84      0.72      0.74       500\n",
      "\n",
      "\n",
      "EXP_11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.67      0.79       384\n",
      "      sexist       0.46      0.91      0.61       116\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.71      0.79      0.70       500\n",
      "weighted avg       0.85      0.73      0.75       500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "for i in results_all[\"sexism\"]['out_of_domain_3'][\"results_GPTdef10\"]:\n",
    "    result_dict = eval(i)\n",
    "#     print(result_dict)\n",
    "for participant in [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\", \"EXP_10\", \"EXP_11\"]:\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"out_of_domain_3\"][participant].values()]\n",
    "    labels = [\"non-sexist\" if i == \"can’t say\" else i for i in labels] \n",
    "    #         print(labels)\n",
    "    truth = results_all[\"sexism\"]['out_of_domain_3'][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.82      0.89       435\n",
      "      sexist       0.41      0.83      0.55        65\n",
      "   sexist\n",
      "\n",
      "1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.46      0.55      0.48       500\n",
      "weighted avg       0.90      0.82      0.85       500\n",
      "\n",
      "\n",
      "EXP_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.84      0.90       435\n",
      "      sexist       0.42      0.78      0.55        65\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.69      0.81      0.72       500\n",
      "weighted avg       0.89      0.83      0.85       500\n",
      "\n",
      "\n",
      "EXP_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.98      0.81      0.88       435\n",
      "      sexist       0.40      0.85      0.54        65\n",
      "   sexist\n",
      "\n",
      "2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.46      0.55      0.48       500\n",
      "weighted avg       0.90      0.81      0.84       500\n",
      "\n",
      "\n",
      "EXP_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.81      0.88       435\n",
      "      sexist       0.40      0.85      0.54        65\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.68      0.83      0.71       500\n",
      "weighted avg       0.90      0.81      0.84       500\n",
      "\n",
      "\n",
      "EXP_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.96      0.84      0.90       435\n",
      "non-sexist\n",
      "2       0.00      0.00      0.00         0\n",
      "      sexist       0.42      0.77      0.55        65\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.46      0.54      0.48       500\n",
      "weighted avg       0.89      0.83      0.85       500\n",
      "\n",
      "\n",
      "EXP_6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.83      0.89       435\n",
      "      sexist       0.42      0.82      0.55        65\n",
      "   sexist\n",
      "\n",
      "1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.46      0.55      0.48       500\n",
      "weighted avg       0.90      0.83      0.85       500\n",
      "\n",
      "\n",
      "EXP_7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.86      0.91       435\n",
      "      sexist       0.46      0.80      0.59        65\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.72      0.83      0.75       500\n",
      "weighted avg       0.90      0.85      0.87       500\n",
      "\n",
      "\n",
      "EXP_8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.85      0.91       435\n",
      "      sexist       0.45      0.82      0.58        65\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.71      0.83      0.74       500\n",
      "weighted avg       0.90      0.85      0.86       500\n",
      "\n",
      "\n",
      "EXP_9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.82      0.89       435\n",
      "      sexist       0.41      0.83      0.55        65\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.69      0.83      0.72       500\n",
      "weighted avg       0.90      0.82      0.85       500\n",
      "\n",
      "\n",
      "EXP_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.81      0.88       435\n",
      "      sexist       0.40      0.85      0.54        65\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.68      0.83      0.71       500\n",
      "weighted avg       0.90      0.81      0.84       500\n",
      "\n",
      "\n",
      "EXP_11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.80      0.88       435\n",
      "non-sexist\n",
      "2       0.00      0.00      0.00         0\n",
      "      sexist       0.39      0.86      0.54        65\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.46      0.55      0.47       500\n",
      "weighted avg       0.90      0.81      0.83       500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "for i in results_all[\"sexism\"]['out_of_domain_2'][\"results_GPTdef10\"]:\n",
    "    result_dict = eval(i)\n",
    "#     print(result_dict)\n",
    "for participant in [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\", \"EXP_10\", \"EXP_11\"]:\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"out_of_domain_2\"][participant].values()]\n",
    "    labels = [\"non-sexist\" if i == \"can’t say\" else i for i in labels] \n",
    "    #         print(labels)\n",
    "    truth = results_all[\"sexism\"]['out_of_domain_2'][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   can't say       0.00      0.00      0.00         0\n",
      "  non-sexist       0.74      0.89      0.81       262\n",
      "      sexist       0.85      0.66      0.75       238\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.53      0.52      0.52       500\n",
      "weighted avg       0.79      0.78      0.78       500\n",
      "\n",
      "\n",
      "EXP_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.70      0.92      0.80       262\n",
      "      sexist       0.86      0.58      0.69       238\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.78      0.75      0.74       500\n",
      "weighted avg       0.78      0.75      0.75       500\n",
      "\n",
      "\n",
      "EXP_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.76      0.89      0.82       262\n",
      "      sexist       0.85      0.70      0.76       238\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.81      0.79      0.79       500\n",
      "weighted avg       0.80      0.80      0.79       500\n",
      "\n",
      "\n",
      "EXP_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.76      0.86      0.81       262\n",
      "      sexist       0.82      0.71      0.76       238\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.79      0.78      0.79       500\n",
      "weighted avg       0.79      0.79      0.79       500\n",
      "\n",
      "\n",
      "EXP_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.74      0.89      0.81       262\n",
      "      sexist       0.85      0.65      0.74       238\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.79      0.77      0.77       500\n",
      "weighted avg       0.79      0.78      0.77       500\n",
      "\n",
      "\n",
      "EXP_6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.75      0.89      0.81       262\n",
      "      sexist       0.85      0.68      0.75       238\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.80      0.78      0.78       500\n",
      "weighted avg       0.80      0.79      0.79       500\n",
      "\n",
      "\n",
      "EXP_7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.74      0.91      0.81       262\n",
      "      sexist       0.87      0.64      0.74       238\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.80      0.78      0.78       500\n",
      "weighted avg       0.80      0.78      0.78       500\n",
      "\n",
      "\n",
      "EXP_8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.73      0.91      0.81       262\n",
      "      sexist       0.86      0.63      0.73       238\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.80      0.77      0.77       500\n",
      "weighted avg       0.79      0.78      0.77       500\n",
      "\n",
      "\n",
      "EXP_9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.75      0.89      0.81       262\n",
      "      sexist       0.84      0.68      0.75       238\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.80      0.78      0.78       500\n",
      "weighted avg       0.79      0.79      0.78       500\n",
      "\n",
      "\n",
      "EXP_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   can't say       0.00      0.00      0.00         0\n",
      "  non-sexist       0.77      0.87      0.82       262\n",
      "      sexist       0.83      0.71      0.77       238\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.53      0.53      0.53       500\n",
      "weighted avg       0.80      0.79      0.79       500\n",
      "\n",
      "\n",
      "EXP_11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.78      0.84      0.81       262\n",
      "      sexist       0.81      0.74      0.77       238\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.80      0.79      0.79       500\n",
      "weighted avg       0.79      0.79      0.79       500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "for i in results_all[\"sexism\"]['out_of_domain'][\"results_GPTdef10\"]:\n",
    "    result_dict = eval(i)\n",
    "#     print(result_dict)\n",
    "for participant in [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\", \"EXP_10\", \"EXP_11\"]:\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"out_of_domain\"][participant].values()]\n",
    "    labels = [\"non-sexist\" if i == \"can’t say\" else i for i in labels] \n",
    "    #         print(labels)\n",
    "    truth = results_all[\"sexism\"]['out_of_domain'][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.93      0.76      0.84       276\n",
      "      sexist       0.76      0.93      0.84       224\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.85      0.85      0.84       500\n",
      "weighted avg       0.86      0.84      0.84       500\n",
      "\n",
      "\n",
      "EXP_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.91      0.77      0.83       276\n",
      "      sexist       0.76      0.91      0.83       224\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.84      0.84      0.83       500\n",
      "weighted avg       0.85      0.83      0.83       500\n",
      "\n",
      "\n",
      "EXP_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.93      0.71      0.81       276\n",
      "      sexist       0.72      0.94      0.82       224\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.83      0.82      0.81       500\n",
      "weighted avg       0.84      0.81      0.81       500\n",
      "\n",
      "\n",
      "EXP_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.94      0.71      0.81       276\n",
      "      sexist       0.73      0.94      0.82       224\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.83      0.83      0.82       500\n",
      "weighted avg       0.84      0.82      0.82       500\n",
      "\n",
      "\n",
      "EXP_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.92      0.77      0.84       276\n",
      "      sexist       0.76      0.92      0.83       224\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.84      0.84      0.84       500\n",
      "weighted avg       0.85      0.84      0.84       500\n",
      "\n",
      "\n",
      "EXP_6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.90      0.74      0.81       276\n",
      "      sexist       0.74      0.90      0.81       224\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.82      0.82      0.81       500\n",
      "weighted avg       0.83      0.81      0.81       500\n",
      "\n",
      "\n",
      "EXP_7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.92      0.76      0.83       276\n",
      "      sexist       0.75      0.92      0.83       224\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.84      0.84      0.83       500\n",
      "weighted avg       0.84      0.83      0.83       500\n",
      "\n",
      "\n",
      "EXP_8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.91      0.76      0.83       276\n",
      "      sexist       0.76      0.91      0.83       224\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.84      0.83       500\n",
      "weighted avg       0.84      0.83      0.83       500\n",
      "\n",
      "\n",
      "EXP_9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.93      0.72      0.81       276\n",
      "      sexist       0.73      0.93      0.82       224\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.83      0.82      0.81       500\n",
      "weighted avg       0.84      0.81      0.81       500\n",
      "\n",
      "\n",
      "EXP_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.94      0.70      0.80       276\n",
      "      sexist       0.72      0.95      0.82       224\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.83      0.82      0.81       500\n",
      "weighted avg       0.84      0.81      0.81       500\n",
      "\n",
      "\n",
      "EXP_11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.95      0.64      0.76       276\n",
      "      sexist       0.68      0.96      0.80       224\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.82      0.80      0.78       500\n",
      "weighted avg       0.83      0.78      0.78       500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "for i in results_all[\"sexism\"]['in_domain'][\"results_GPTdef10\"]:\n",
    "    result_dict = eval(i)\n",
    "#     print(result_dict)\n",
    "for participant in [\"EXP_1\", \"EXP_2\", \"EXP_3\", \"EXP_4\", \"EXP_5\", \"EXP_6\", \"EXP_7\", \"EXP_8\", \"EXP_9\", \"EXP_10\", \"EXP_11\"]:\n",
    "    print(participant)\n",
    "    labels = [i.split(\")\")[1].strip().split(\".\")[0] for i in result_dict[\"in_domain\"][participant].values()]\n",
    "    labels = [\"non-sexist\" if i == \"can’t say\" else i for i in labels] \n",
    "    #         print(labels)\n",
    "    truth = results_all[\"sexism\"]['in_domain'][\"sexism\"].tolist()\n",
    "    print(classification_report(truth, labels))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "65037a40e934b14503404e412a10b71c3933ce023a0cd46a7e5dc61bdd2dc8b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
